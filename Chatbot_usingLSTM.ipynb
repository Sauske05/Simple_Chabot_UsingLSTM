{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a6fdb35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83462385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.4 (tags/v3.9.4:1f2e308, Apr  6 2021, 13:40:21) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c3bdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Mon_Nov_30_19:15:10_Pacific_Standard_Time_2020\n",
      "Cuda compilation tools, release 11.2, V11.2.67\n",
      "Build cuda_11.2.r11.2/compiler.29373293_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cadd44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c270be7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# List all available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "for gpu in gpus:\n",
    "    print(\"GPU:\", gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fed1cf45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3409082934.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    set TF_CPP_MIN_LOG_LEVEL=1\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37aecd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "# Import TensorFlow and run your code\n",
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# List all available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "for gpu in gpus:\n",
    "    print(\"GPU:\", gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d56e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12bd5d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 19 11:45:59 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 532.03                 Driver Version: 532.03       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650       WDDM | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   46C    P8                4W /  N/A|    548MiB /  4096MiB |      2%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1144    C+G   ...e Stream\\92.0.0.0\\GoogleDriveFS.exe    N/A      |\n",
      "|    0   N/A  N/A      3176    C+G   ...bs\\Common\\Client\\v1.4.2\\rsAppUI.exe    N/A      |\n",
      "|    0   N/A  N/A      7588    C+G   ...inaries\\Win64\\EpicGamesLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A      9116    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      9536    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A      9760    C+G   ...8.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9876    C+G   ...ne\\Binaries\\Win64\\EpicWebHelper.exe    N/A      |\n",
      "|    0   N/A  N/A     10516    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     11860    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11992    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     12420    C+G   C:\\Windows\\System32\\dwm.exe               N/A      |\n",
      "|    0   N/A  N/A     18084    C+G   ...on\\126.0.2592.61\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     19720    C+G   ...aam7r\\AcrobatNotificationClient.exe    N/A      |\n",
      "|    0   N/A  N/A     20296    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     21076    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     21756    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     22652    C+G   ...bs\\Common\\Client\\v1.4.2\\rsAppUI.exe    N/A      |\n",
      "|    0   N/A  N/A     26072    C+G   ...bs\\Common\\Client\\v1.4.2\\rsAppUI.exe    N/A      |\n",
      "|    0   N/A  N/A     26724    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e75fc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuDNN version: cuDNN version file not found.\n"
     ]
    }
   ],
   "source": [
    "def get_cudnn_version():\n",
    "    try:\n",
    "        with open('/usr/local/cuda/include/cudnn_version.h', 'r') as f:\n",
    "            for line in f:\n",
    "                if 'CUDNN_MAJOR' in line:\n",
    "                    major_version = line.split()[-1]\n",
    "                if 'CUDNN_MINOR' in line:\n",
    "                    minor_version = line.split()[-1]\n",
    "                if 'CUDNN_PATCHLEVEL' in line:\n",
    "                    patch_version = line.split()[-1]\n",
    "            return f\"{major_version}.{minor_version}.{patch_version}\"\n",
    "    except FileNotFoundError:\n",
    "        return \"cuDNN version file not found.\"\n",
    "\n",
    "print(f\"cuDNN version: {get_cudnn_version()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5af7f7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Mon_Nov_30_19:15:10_Pacific_Standard_Time_2020\n",
      "Cuda compilation tools, release 11.2, V11.2.67\n",
      "Build cuda_11.2.r11.2/compiler.29373293_0\n",
      "cuDNN version: cuDNN version file not found.\n"
     ]
    }
   ],
   "source": [
    "# Checking CUDA version\n",
    "try:\n",
    "    !nvcc --version\n",
    "except:\n",
    "    print(\"nvcc not found. Ensure that CUDA is installed and nvcc is in your PATH.\")\n",
    "\n",
    "# Checking cuDNN version\n",
    "def get_cudnn_version():\n",
    "    try:\n",
    "        with open('/usr/local/cuda/include/cudnn_version.h', 'r') as f:\n",
    "            for line in f:\n",
    "                if 'CUDNN_MAJOR' in line:\n",
    "                    major_version = line.split()[-1]\n",
    "                if 'CUDNN_MINOR' in line:\n",
    "                    minor_version = line.split()[-1]\n",
    "                if 'CUDNN_PATCHLEVEL' in line:\n",
    "                    patch_version = line.split()[-1]\n",
    "            return f\"{major_version}.{minor_version}.{patch_version}\"\n",
    "    except FileNotFoundError:\n",
    "        return \"cuDNN version file not found.\"\n",
    "\n",
    "print(f\"cuDNN version: {get_cudnn_version()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3df590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available and set memory growth to avoid taking all GPU memory\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4f57c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c41f6496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"id\": \"L1045\", \"conversation_id\": \"L1044\", \"text\": \"They do not!\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"not\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L1044\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L1044\", \"conversation_id\": \"L1044\", \"text\": \"They do to!\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"dobj\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L985\", \"conversation_id\": \"L984\", \"text\": \"I hope so.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"hope\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"so\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 1, \"dn\": []}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L984\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L984\", \"conversation_id\": \"L984\", \"text\": \"She okay?\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"She\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"okay\", \"tag\": \"RB\", \"dep\": \"ROOT\", \"dn\": [0, 2]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L925\", \"conversation_id\": \"L924\", \"text\": \"Let\\'s go.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Let\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [2, 3]}, {\"tok\": \"\\'s\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"go\", \"tag\": \"VB\", \"dep\": \"ccomp\", \"up\": 0, \"dn\": [1]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L924\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L924\", \"conversation_id\": \"L924\", \"text\": \"Wow\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Wow\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L872\", \"conversation_id\": \"L870\", \"text\": \"Okay -- you\\'re gonna need to learn how to lie.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 4, \"toks\": [{\"tok\": \"Okay\", \"tag\": \"UH\", \"dep\": \"intj\", \"up\": 4, \"dn\": []}, {\"tok\": \"--\", \"tag\": \":\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"\\'re\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"gon\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 6, 12]}, {\"tok\": \"na\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 6, \"dn\": []}, {\"tok\": \"need\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 8]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 8, \"dn\": []}, {\"tok\": \"learn\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 6, \"dn\": [7, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 11, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 11, \"dn\": []}, {\"tok\": \"lie\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 8, \"dn\": [9, 10]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": \"L871\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L871\", \"conversation_id\": \"L870\", \"text\": \"No\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"No\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": \"L870\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L870\", \"conversation_id\": \"L870\", \"text\": \"I\\'m kidding.  You know how sometimes you just become this \\\\\"persona\\\\\"?  And you don\\'t know how to quit?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 2, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"\\'m\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 2, \"dn\": []}, {\"tok\": \"kidding\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 3]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 2, \"dn\": [4]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 3, \"dn\": []}]}, {\"rt\": 1, \"toks\": [{\"tok\": \"You\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 6, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 3, \"dn\": []}, {\"tok\": \"sometimes\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": [2]}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 6, \"dn\": []}, {\"tok\": \"just\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": []}, {\"tok\": \"become\", \"tag\": \"VBP\", \"dep\": \"ccomp\", \"up\": 1, \"dn\": [3, 4, 5, 9]}, {\"tok\": \"this\", \"tag\": \"DT\", \"dep\": \"det\", \"up\": 9, \"dn\": []}, {\"tok\": \"\\\\\"\", \"tag\": \"``\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"persona\", \"tag\": \"NN\", \"dep\": \"attr\", \"up\": 6, \"dn\": [7, 8, 10]}, {\"tok\": \"\\\\\"\", \"tag\": \"\\'\\'\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": [12]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 11, \"dn\": []}]}, {\"rt\": 4, \"toks\": [{\"tok\": \"And\", \"tag\": \"CC\", \"dep\": \"cc\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"n\\'t\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 4, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 7, 8]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 7, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 7, \"dn\": []}, {\"tok\": \"quit\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 6]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L869\", \"conversation_id\": \"L866\", \"text\": \"Like my fear of wearing pastels?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Like\", \"tag\": \"IN\", \"dep\": \"ROOT\", \"dn\": [2, 6]}, {\"tok\": \"my\", \"tag\": \"PRP$\", \"dep\": \"poss\", \"up\": 2, \"dn\": []}, {\"tok\": \"fear\", \"tag\": \"NN\", \"dep\": \"pobj\", \"up\": 0, \"dn\": [1, 3]}, {\"tok\": \"of\", \"tag\": \"IN\", \"dep\": \"prep\", \"up\": 2, \"dn\": [4]}, {\"tok\": \"wearing\", \"tag\": \"VBG\", \"dep\": \"pcomp\", \"up\": 3, \"dn\": [5]}, {\"tok\": \"pastels\", \"tag\": \"NNS\", \"dep\": \"dobj\", \"up\": 4, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L868\", \"timestamp\": null, \"vectors\": []}\\n'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import json\n",
    "\n",
    "corpus_name = \"movie-corpus\"\n",
    "corpus = os.path.join(\"data\", corpus_name)\n",
    "\n",
    "def printLines(file, n=10):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "printLines(os.path.join(corpus, \"utterances.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5480f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits each line of the file to create lines and conversations\n",
    "def loadLinesAndConversations(fileName, n):\n",
    "    lines = {}\n",
    "    conversations = {}\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            lineJson = json.loads(line)\n",
    "            # Extract fields for line object\n",
    "            lineObj = {}\n",
    "            lineObj[\"lineID\"] = lineJson[\"id\"] #example : L1045\n",
    "            lineObj[\"characterID\"] = lineJson[\"speaker\"] # example : u1, u2\n",
    "            lineObj[\"text\"] = lineJson[\"text\"] #These are the conversations\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "\n",
    "            # Extract fields for conversation object\n",
    "            if lineJson[\"conversation_id\"] not in conversations:\n",
    "                convObj = {}\n",
    "                convObj[\"conversationID\"] = lineJson[\"conversation_id\"]\n",
    "                convObj[\"movieID\"] = lineJson[\"meta\"][\"movie_id\"]\n",
    "                convObj[\"lines\"] = [lineObj]\n",
    "            else:\n",
    "                convObj = conversations[lineJson[\"conversation_id\"]]\n",
    "                convObj[\"lines\"].insert(0, lineObj)\n",
    "            conversations[convObj[\"conversationID\"]] = convObj\n",
    "    first_n_items = dict(itertools.islice(lines.items(), n))\n",
    "    print(first_n_items)\n",
    "    print(\"Line dictionary ends!! \\n\")\n",
    "    second_n_items = dict(itertools.islice(conversations.items(), n))\n",
    "    print(second_n_items)\n",
    "\n",
    "    return lines, conversations\n",
    "\n",
    "\n",
    "# Extracts pairs of sentences from conversations\n",
    "def extractSentencePairs(conversations):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations.values():\n",
    "        # Iterate over all the lines of the conversation\n",
    "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # Filter wrong samples (if one of the lists is empty)\n",
    "            if inputLine and targetLine:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f048a2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus into lines and conversations...\n",
      "{'L1045': {'lineID': 'L1045', 'characterID': 'u0', 'text': 'They do not!'}, 'L1044': {'lineID': 'L1044', 'characterID': 'u2', 'text': 'They do to!'}, 'L985': {'lineID': 'L985', 'characterID': 'u0', 'text': 'I hope so.'}, 'L984': {'lineID': 'L984', 'characterID': 'u2', 'text': 'She okay?'}, 'L925': {'lineID': 'L925', 'characterID': 'u0', 'text': \"Let's go.\"}, 'L924': {'lineID': 'L924', 'characterID': 'u2', 'text': 'Wow'}, 'L872': {'lineID': 'L872', 'characterID': 'u0', 'text': \"Okay -- you're gonna need to learn how to lie.\"}, 'L871': {'lineID': 'L871', 'characterID': 'u2', 'text': 'No'}, 'L870': {'lineID': 'L870', 'characterID': 'u0', 'text': 'I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?'}, 'L869': {'lineID': 'L869', 'characterID': 'u0', 'text': 'Like my fear of wearing pastels?'}}\n",
      "Line dictionary ends!! \n",
      "\n",
      "{'L1044': {'conversationID': 'L1044', 'movieID': 'm0', 'lines': [{'lineID': 'L1044', 'characterID': 'u2', 'text': 'They do to!'}, {'lineID': 'L1045', 'characterID': 'u0', 'text': 'They do not!'}]}, 'L984': {'conversationID': 'L984', 'movieID': 'm0', 'lines': [{'lineID': 'L984', 'characterID': 'u2', 'text': 'She okay?'}, {'lineID': 'L985', 'characterID': 'u0', 'text': 'I hope so.'}]}, 'L924': {'conversationID': 'L924', 'movieID': 'm0', 'lines': [{'lineID': 'L924', 'characterID': 'u2', 'text': 'Wow'}, {'lineID': 'L925', 'characterID': 'u0', 'text': \"Let's go.\"}]}, 'L870': {'conversationID': 'L870', 'movieID': 'm0', 'lines': [{'lineID': 'L870', 'characterID': 'u0', 'text': 'I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?'}, {'lineID': 'L871', 'characterID': 'u2', 'text': 'No'}, {'lineID': 'L872', 'characterID': 'u0', 'text': \"Okay -- you're gonna need to learn how to lie.\"}]}, 'L866': {'conversationID': 'L866', 'movieID': 'm0', 'lines': [{'lineID': 'L866', 'characterID': 'u2', 'text': \"I figured you'd get to the good stuff eventually.\"}, {'lineID': 'L867', 'characterID': 'u0', 'text': 'What good stuff?'}, {'lineID': 'L868', 'characterID': 'u2', 'text': 'The \"real you\".'}, {'lineID': 'L869', 'characterID': 'u0', 'text': 'Like my fear of wearing pastels?'}]}, 'L862': {'conversationID': 'L862', 'movieID': 'm0', 'lines': [{'lineID': 'L862', 'characterID': 'u0', 'text': 'do you listen to this crap?'}, {'lineID': 'L863', 'characterID': 'u2', 'text': 'What crap?'}, {'lineID': 'L864', 'characterID': 'u0', 'text': \"Me.  This endless ...blonde babble. I'm like, boring myself.\"}, {'lineID': 'L865', 'characterID': 'u2', 'text': 'Thank God!  If I had to hear one more story about your coiffure...'}]}, 'L860': {'conversationID': 'L860', 'movieID': 'm0', 'lines': [{'lineID': 'L860', 'characterID': 'u0', 'text': 'Then Guillermo says, \"If you go any lighter, you\\'re gonna look like an extra on 90210.\"'}, {'lineID': 'L861', 'characterID': 'u2', 'text': 'No...'}]}, 'L696': {'conversationID': 'L696', 'movieID': 'm0', 'lines': [{'lineID': 'L696', 'characterID': 'u0', 'text': 'Well, no...'}, {'lineID': 'L697', 'characterID': 'u2', 'text': \"Then that's all you had to say.\"}, {'lineID': 'L698', 'characterID': 'u0', 'text': 'But'}, {'lineID': 'L699', 'characterID': 'u2', 'text': 'You always been this selfish?'}]}, 'L693': {'conversationID': 'L693', 'movieID': 'm0', 'lines': [{'lineID': 'L693', 'characterID': 'u2', 'text': 'I looked for you back at the party, but you always seemed to be \"occupied\".'}, {'lineID': 'L694', 'characterID': 'u0', 'text': 'I was?'}, {'lineID': 'L695', 'characterID': 'u2', 'text': \"You never wanted to go out with 'me, did you?\"}]}, 'L662': {'conversationID': 'L662', 'movieID': 'm0', 'lines': [{'lineID': 'L662', 'characterID': 'u2', 'text': 'Have fun tonight?'}, {'lineID': 'L663', 'characterID': 'u0', 'text': 'Tons'}]}}\n",
      "\n",
      "Writing newly formatted file...\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import itertools\n",
    "# Define path to new file\n",
    "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
    "\n",
    "delimiter = ','\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "# Initialize lines dict and conversations dict\n",
    "lines = {}\n",
    "conversations = {}\n",
    "# Load lines and conversations\n",
    "print(\"\\nProcessing corpus into lines and conversations...\")\n",
    "lines, conversations = loadLinesAndConversations(os.path.join(corpus, \"utterances.jsonl\"), 10)\n",
    "\n",
    "# Write new csv file\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "# with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "#     writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "#     for pair in extractSentencePairs(conversations):\n",
    "#         writer.writerow(pair)\n",
    "\n",
    "# # Print a sample of lines\n",
    "# print(\"\\nSample lines from file:\")\n",
    "# printLines(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795f8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/movie-corpus/formatted_movie_lines.txt\")\n",
    "# Define the text to add\n",
    "import re\n",
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
    "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
    "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
    "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
    "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
    "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
    "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
    "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
    "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
    "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
    "    return txt\n",
    "df['Input'] = df['Input'].apply(lambda x: clean_text(x))\n",
    "df['Output'] = df['Output'].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ac0f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; they do to &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; they do not &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; she okay &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; i hope so &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; wow &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; lets go &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; i am kidding  you know how sometimes you...</td>\n",
       "      <td>&lt;SOS&gt; no &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; no &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; okay  you are gonna need to learn how to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221277</th>\n",
       "      <td>&lt;SOS&gt; and i assure you you do not in fact i wo...</td>\n",
       "      <td>&lt;SOS&gt; so far only their scouts but we have had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221278</th>\n",
       "      <td>&lt;SOS&gt; your orders mr vereker &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; i am to take the sikali with the main co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221279</th>\n",
       "      <td>&lt;SOS&gt; i am to take the sikali with the main co...</td>\n",
       "      <td>&lt;SOS&gt; lord chelmsford seems to want me to stay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221280</th>\n",
       "      <td>&lt;SOS&gt; lord chelmsford seems to want me to stay...</td>\n",
       "      <td>&lt;SOS&gt; i think chelmsford wants a good man on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221281</th>\n",
       "      <td>&lt;SOS&gt; colonel durnford william vereker i hear ...</td>\n",
       "      <td>&lt;SOS&gt; good ones yes mr vereker gentlemen who c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221282 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Input  \\\n",
       "0                                  <SOS> they do to <EOS>   \n",
       "1                                    <SOS> she okay <EOS>   \n",
       "2                                         <SOS> wow <EOS>   \n",
       "3       <SOS> i am kidding  you know how sometimes you...   \n",
       "4                                          <SOS> no <EOS>   \n",
       "...                                                   ...   \n",
       "221277  <SOS> and i assure you you do not in fact i wo...   \n",
       "221278                 <SOS> your orders mr vereker <EOS>   \n",
       "221279  <SOS> i am to take the sikali with the main co...   \n",
       "221280  <SOS> lord chelmsford seems to want me to stay...   \n",
       "221281  <SOS> colonel durnford william vereker i hear ...   \n",
       "\n",
       "                                                   Output  \n",
       "0                                 <SOS> they do not <EOS>  \n",
       "1                                   <SOS> i hope so <EOS>  \n",
       "2                                     <SOS> lets go <EOS>  \n",
       "3                                          <SOS> no <EOS>  \n",
       "4       <SOS> okay  you are gonna need to learn how to...  \n",
       "...                                                   ...  \n",
       "221277  <SOS> so far only their scouts but we have had...  \n",
       "221278  <SOS> i am to take the sikali with the main co...  \n",
       "221279  <SOS> lord chelmsford seems to want me to stay...  \n",
       "221280  <SOS> i think chelmsford wants a good man on t...  \n",
       "221281  <SOS> good ones yes mr vereker gentlemen who c...  \n",
       "\n",
       "[221282 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_text = '<SOS> '\n",
    "end_text = ' <EOS>'\n",
    "\n",
    "# Add text to the specific column 'A'\n",
    "df['Input'] = df['Input'].apply(lambda x: f\"{start_text }{x}{ end_text}\")\n",
    "df['Output'] = df['Output'].apply(lambda x: f\"{start_text }{x}{ end_text}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c6e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a6a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SOS>', 'they', 'do', 'to', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "# Function to preprocess while preserving <SOS> and <EOS>\n",
    "def preprocess_with_tags(text):\n",
    "    words = text.split()\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        if word in [\"<SOS>\", \"<EOS>\"]:\n",
    "            processed_words.append(word)\n",
    "        else:\n",
    "            processed_words.extend(gensim.utils.simple_preprocess(word))\n",
    "    return processed_words\n",
    "\n",
    "# Sample text\n",
    "review_text = \"<SOS> they do to <EOS>\"\n",
    "\n",
    "# Preprocess the text\n",
    "processed_text = preprocess_with_tags(review_text)\n",
    "\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f30fe16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    <SOS> they do to <EOS>\n",
       "1                                      <SOS> she okay <EOS>\n",
       "2                                           <SOS> wow <EOS>\n",
       "3         <SOS> i am kidding  you know how sometimes you...\n",
       "4                                            <SOS> no <EOS>\n",
       "                                ...                        \n",
       "442559    <SOS> so far only their scouts but we have had...\n",
       "442560    <SOS> i am to take the sikali with the main co...\n",
       "442561    <SOS> lord chelmsford seems to want me to stay...\n",
       "442562    <SOS> i think chelmsford wants a good man on t...\n",
       "442563    <SOS> good ones yes mr vereker gentlemen who c...\n",
       "Length: 442564, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_column = pd.concat([df_copy['Input'], df_copy['Output']], ignore_index=True)\n",
    "new_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57398ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = new_column.apply(lambda x: preprocess_with_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "388bb7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8220db3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<SOS>', 'what', 'crap', '<EOS>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text.loc[221290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67287ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 25708\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=4,\n",
    "    workers=4,\n",
    ")\n",
    "model.build_vocab(review_text, progress_per=1000)\n",
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "vocab_size = len(model.wv.key_to_index)\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd0067f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for the word 'morning':\n",
      "[-1.2369996   0.7844137  -0.44057974 -0.2507683   1.0759501  -1.1496592\n",
      "  1.7101052   0.06473897  0.33961076  0.62848485 -0.8928867  -1.866862\n",
      " -2.5816033  -1.0005865   2.271988   -2.2612495  -1.0961847   1.4637603\n",
      "  0.0997449  -0.9419414   1.4201994   1.6473341   2.3067703   2.271057\n",
      "  0.3548921   2.8069959  -0.8556213  -1.7563701   0.25217834  0.48769122\n",
      "  0.9673723  -3.4992812   2.1219492   2.9991107   2.2594569  -1.0255175\n",
      "  1.0638573   1.7968904   0.15132338  1.525712   -3.5287032  -2.6841\n",
      "  1.9038767   0.6758719   0.46601656  1.7582185  -2.0105622   0.51091343\n",
      "  0.32496673  0.84498835 -0.22838153 -3.8356922   0.5345636   0.5964998\n",
      " -2.3626266  -2.655604   -0.29403135 -1.7368778  -0.9660204   0.4644031\n",
      "  0.49597052 -0.44986212  0.24034013  0.17344113  0.21897085  1.604822\n",
      "  0.7974974  -0.79548824 -1.8390288  -0.34217596 -0.79229903  1.4550328\n",
      " -2.0460598   1.2295457   2.3271258   0.06000877 -0.20206848 -0.99426085\n",
      " -0.7353292   1.6674099  -1.9459124   0.20683737  0.27662903 -0.7838625\n",
      " -0.52079874  1.0386338   1.4605104  -1.6822851  -2.2950327  -1.9325631\n",
      " -0.891331   -0.49726918 -0.50711614 -1.5829412  -0.9813544   0.19396865\n",
      " -1.944345    2.7956617  -1.3316078  -1.7506554 ]\n"
     ]
    }
   ],
   "source": [
    "def search_word_vector(model, word):\n",
    "    if word in model.wv.key_to_index:\n",
    "        vector = model.wv[word]\n",
    "        print(f\"Vector for the word '{word}':\\n{vector}\")\n",
    "    else:\n",
    "        print(f\"The word '{word}' is not in the vocabulary.\")\n",
    "\n",
    "search_word_vector(model, \"morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd0fd628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('afternoon', 0.803367555141449),\n",
       " ('evening', 0.7073668837547302),\n",
       " ('weekend', 0.6484994292259216),\n",
       " ('mornin', 0.61491858959198),\n",
       " ('week', 0.612152099609375),\n",
       " ('summer', 0.5927719473838806),\n",
       " ('flight', 0.5903869867324829),\n",
       " ('today', 0.5751970410346985),\n",
       " ('thursday', 0.5714535117149353),\n",
       " ('night', 0.5594099760055542)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13303902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<SOS>': array([ 2.5916567 ,  1.4283063 ,  1.0212036 , -0.858082  , -0.3097519 ,\n",
      "       -1.6708245 ,  0.98272175,  0.90748805, -1.4541744 ,  0.19221294,\n",
      "        0.9256307 ,  0.6355444 , -1.652382  ,  1.429644  , -0.877997  ,\n",
      "        0.21235612, -0.5248258 ,  0.565508  ,  0.1840984 , -0.43009928,\n",
      "        0.682442  ,  0.8885291 , -0.7742787 , -0.0921006 ,  0.859569  ,\n",
      "       -0.5414446 ,  0.70691484, -1.0275972 , -0.28413308,  0.97960246,\n",
      "       -1.0276887 , -0.08433787,  0.28652504, -0.29455683, -0.17823157,\n",
      "       -0.4961545 ,  1.1285073 , -0.7516295 ,  1.0653925 ,  1.2000936 ,\n",
      "       -0.94580775, -0.527489  , -1.3799243 ,  0.5297313 ,  0.44838294,\n",
      "        1.4850606 , -1.016053  , -0.9836363 , -0.27249828,  2.6834705 ,\n",
      "       -1.1395487 , -0.6571377 ,  0.0900977 , -0.54008937, -0.6927273 ,\n",
      "        1.6881183 ,  0.1882551 , -1.548708  ,  0.8939718 ,  1.8361596 ,\n",
      "       -0.7282715 ,  0.74863523, -1.3596723 ,  0.82660687,  1.8090012 ,\n",
      "       -0.03178599,  0.4817959 , -0.22609441, -0.76331824,  1.6272978 ,\n",
      "       -0.47133598, -0.6266224 , -1.3791177 ,  1.7453465 ,  0.34594753,\n",
      "       -0.56066203,  0.9649557 ,  0.36034858, -1.0622909 , -0.8957492 ,\n",
      "       -1.5235119 ,  0.26153275,  0.37848988,  0.14940144, -1.2672664 ,\n",
      "       -0.06041943, -0.37941945, -1.9136918 ,  0.08035874,  0.17241105,\n",
      "       -0.7072644 , -0.6759499 , -0.02358783,  0.43665993,  0.6527474 ,\n",
      "        0.8267626 ,  0.01815964, -1.1028557 ,  0.2259404 , -0.98895186],\n",
      "      dtype=float32), '<EOS>': array([ 1.071439  ,  0.6737246 ,  0.2291265 ,  0.4730969 ,  0.46964782,\n",
      "       -1.5601077 ,  0.24052994,  0.66280425,  0.7560579 ,  0.5629001 ,\n",
      "        0.9930415 ,  0.22619063, -0.12933008,  0.11528583,  0.16206235,\n",
      "       -0.1632134 , -0.3598167 , -0.7685785 , -1.1952683 ,  0.09587889,\n",
      "        0.25467503, -0.20047136, -0.93295676,  0.6219137 ,  0.99590427,\n",
      "        0.39296982,  0.10672142,  0.3047702 , -0.57695967,  0.83806294,\n",
      "        0.09376106, -1.0669171 , -0.31579226, -0.1366777 ,  0.04611401,\n",
      "       -0.6987586 ,  0.22567634, -0.23849696, -0.58052963, -0.7399004 ,\n",
      "       -0.49906853, -1.0982629 ,  0.0414573 ,  1.0530347 , -1.4203397 ,\n",
      "        0.10502852,  0.5651021 , -0.3951637 , -0.45420727,  0.6021475 ,\n",
      "       -0.07333931, -0.45426792,  0.62988496, -0.11668355, -1.488159  ,\n",
      "        1.0398401 ,  0.54428315, -0.5214992 ,  0.47743717,  0.31067878,\n",
      "       -0.9242022 , -0.8069973 ,  0.05342031,  0.7317196 , -0.4150855 ,\n",
      "       -0.10063433,  1.051501  ,  0.10644417, -1.463732  ,  0.5500406 ,\n",
      "       -1.215132  , -0.19298317, -0.63121   ,  1.5895422 ,  0.69587016,\n",
      "       -0.46677357, -1.370841  ,  0.6951841 , -1.1818871 ,  0.1589701 ,\n",
      "        0.1833699 , -0.16912623, -0.04133761,  0.05134305, -0.08565395,\n",
      "        0.2908837 , -0.00263338,  0.4040054 , -0.83824503,  0.46622646,\n",
      "       -0.3801044 , -0.42849237,  0.8023376 ,  0.3598074 , -0.25279486,\n",
      "       -0.39456782,  0.04443311,  0.8988934 ,  0.34479412, -0.46113047],\n",
      "      dtype=float32), 'you': array([ 3.5812428 ,  0.8437552 , -2.9792397 ,  0.18969537,  0.9554978 ,\n",
      "       -0.9922895 ,  0.88727134, -1.2305024 ,  0.57641125,  0.9011901 ,\n",
      "        1.3461837 ,  2.6022418 , -1.0476674 , -1.5484865 , -0.88285404,\n",
      "        0.4874284 , -2.1154628 , -1.1461176 , -2.7670925 ,  0.1334287 ,\n",
      "        2.4049559 , -0.5104918 , -1.5449966 , -1.5976074 ,  2.0045402 ,\n",
      "       -0.65487045,  2.8755147 , -0.32792753, -0.8808605 ,  1.4723042 ,\n",
      "       -0.668486  , -1.0867983 , -0.8273364 , -0.6461478 ,  0.8063514 ,\n",
      "       -1.188891  , -0.03479124, -2.5286992 , -1.1670418 , -0.5772085 ,\n",
      "       -2.3312469 , -0.24274723, -0.8856852 ,  2.7928002 ,  0.5847855 ,\n",
      "        1.8392572 , -1.3189733 ,  0.04776708, -2.218422  ,  1.6706892 ,\n",
      "        1.7129409 , -1.871227  , -0.40142968, -2.018289  , -0.5702916 ,\n",
      "        0.4832769 , -0.18540934, -1.856215  ,  0.2865582 ,  1.7077347 ,\n",
      "       -1.1585178 , -0.2340809 , -0.08866146, -0.3211178 ,  0.79990655,\n",
      "        1.9205881 ,  0.8783455 , -1.9305749 , -1.8120961 ,  0.79690826,\n",
      "       -0.24974048,  0.9641668 ,  0.67650896,  0.9481924 , -1.1700901 ,\n",
      "       -0.5431114 ,  0.58421767,  1.4374334 , -2.0645115 ,  0.02783772,\n",
      "       -2.945129  , -0.8822632 , -1.7400544 , -2.2095287 , -0.13645598,\n",
      "        0.619491  ,  0.49520922, -0.75743616,  1.2546076 , -0.17314586,\n",
      "       -1.1923858 , -1.816312  ,  0.06976277, -0.23647177,  0.2842738 ,\n",
      "        0.33740127,  1.8505478 ,  1.692584  ,  0.6728371 ,  1.061229  ],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary\n",
    "word_vectors = {}\n",
    "\n",
    "# Iterate through the vocabulary\n",
    "for word in model.wv.index_to_key:\n",
    "    # Add the word and its vector to the dictionary\n",
    "    #print(type( model.wv[word]))\n",
    "    word_vectors[word] = model.wv[word]\n",
    "\n",
    "# Now word_vectors is a dictionary with words as keys and vectors as values\n",
    "top_three_word_vectors = dict(list(word_vectors.items())[:3])\n",
    "print(top_three_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "120d6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "key1 = '<OUT>'\n",
    "value1 = [1] * 100\n",
    "key2 = '<PAD>'\n",
    "value2 = [0] * 100\n",
    "word_vectors[key1] = np.array(value1, dtype=np.float32)\n",
    "word_vectors[key2] = np.array(value2, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d289678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OUT>\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "<PAD>\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for key, values in word_vectors.items():\n",
    "    if key == '<OUT>' or key == '<PAD>':\n",
    "        print(key)\n",
    "        print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f2eaa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "a = \"Hello I am G\"\n",
    "count = 0\n",
    "for i in a.split():\n",
    "    count +=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec5958ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS> they do to <EOS>\n",
      "['<SOS>', 'they', 'do', 'to', '<EOS>']\n",
      "<SOS> she okay <EOS>\n",
      "['<SOS>', 'she', 'okay', '<EOS>']\n",
      "<SOS> wow <EOS>\n",
      "['<SOS>', 'wow', '<EOS>']\n",
      "<SOS> i am kidding  you know how sometimes you just become this persona  and you dont know how to quit <EOS>\n",
      "['<SOS>', 'i', 'am', 'kidding', 'you', 'know', 'how', 'sometimes', 'you', 'just', 'become', 'this', 'persona', 'and', 'you', 'dont', 'know', 'how', 'to', 'quit', '<EOS>']\n",
      "<SOS> no <EOS>\n",
      "['<SOS>', 'no', '<EOS>']\n",
      "<SOS> i figured you would get to the good stuff eventually <EOS>\n",
      "['<SOS>', 'i', 'figured', 'you', 'would', 'get', 'to', 'the', 'good', 'stuff', 'eventually', '<EOS>']\n",
      "<SOS> what good stuff <EOS>\n",
      "['<SOS>', 'what', 'good', 'stuff', '<EOS>']\n",
      "<SOS> the real you <EOS>\n",
      "['<SOS>', 'the', 'real', 'you', '<EOS>']\n",
      "<SOS> do you listen to this crap <EOS>\n",
      "['<SOS>', 'do', 'you', 'listen', 'to', 'this', 'crap', '<EOS>']\n",
      "<SOS> what crap <EOS>\n",
      "['<SOS>', 'what', 'crap', '<EOS>']\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "for entry in list(new_column)[:10]:\n",
    "    # Split the entry by spaces to get the words\n",
    "    print(entry)\n",
    "    words = entry.split()\n",
    "    print(words)\n",
    "    # Get the number of words\n",
    "    count_words = len(words)\n",
    "    # Update the max_length if the current count is greater\n",
    "    if count_words > max_length:\n",
    "        max_length = count_words\n",
    "\n",
    "# Print the maximum length of words\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4a851c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the pre-trained Word2Vec model\n",
    "#model = Word2Vec.load(\"./data/movie-corpus/word2vec.model\")\n",
    "\n",
    "# Convert sentences to sequences of vectors\n",
    "\n",
    "def sentence_to_vectors(sentence):\n",
    "    gensim_sentences_list = preprocess_with_tags(sentence)\n",
    "    #vectors = [model.wv[word] for word in gensim_sentences_list if word in model.wv]\n",
    "#     vectors = [word_vectors[word] for word in word_vectors.keys() if word in wor]\n",
    "    vectors= []\n",
    "    for word in gensim_sentences_list:\n",
    "        if word in word_vectors.keys():\n",
    "            vectors.append(word_vectors[word])\n",
    "        else:\n",
    "            vectors.append(word_vectors['<OUT>'])\n",
    "        \n",
    "        \n",
    "#     for word in sentence.lower.split():\n",
    "#         if word.contains(\"'\")\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0435d0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221282, 13, 100) (221282, 13, 100)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 2.5916567   1.4283063   1.0212036  -0.858082   -0.3097519  -1.6708245\n",
      "  0.98272175  0.90748805 -1.4541744   0.19221294  0.9256307   0.6355444\n",
      " -1.652382    1.429644   -0.877997    0.21235612 -0.5248258   0.565508\n",
      "  0.1840984  -0.43009928  0.682442    0.8885291  -0.7742787  -0.0921006\n",
      "  0.859569   -0.5414446   0.70691484 -1.0275972  -0.28413308  0.97960246\n",
      " -1.0276887  -0.08433787  0.28652504 -0.29455683 -0.17823157 -0.4961545\n",
      "  1.1285073  -0.7516295   1.0653925   1.2000936  -0.94580775 -0.527489\n",
      " -1.3799243   0.5297313   0.44838294  1.4850606  -1.016053   -0.9836363\n",
      " -0.27249828  2.6834705  -1.1395487  -0.6571377   0.0900977  -0.54008937\n",
      " -0.6927273   1.6881183   0.1882551  -1.548708    0.8939718   1.8361596\n",
      " -0.7282715   0.74863523 -1.3596723   0.82660687  1.8090012  -0.03178599\n",
      "  0.4817959  -0.22609441 -0.76331824  1.6272978  -0.47133598 -0.6266224\n",
      " -1.3791177   1.7453465   0.34594753 -0.56066203  0.9649557   0.36034858\n",
      " -1.0622909  -0.8957492  -1.5235119   0.26153275  0.37848988  0.14940144\n",
      " -1.2672664  -0.06041943 -0.37941945 -1.9136918   0.08035874  0.17241105\n",
      " -0.7072644  -0.6759499  -0.02358783  0.43665993  0.6527474   0.8267626\n",
      "  0.01815964 -1.1028557   0.2259404  -0.98895186]\n",
      "(100,)\n",
      "This is the model vector size 100\n"
     ]
    }
   ],
   "source": [
    "df_copy['input_vectors'] = df_copy['Input'].apply(sentence_to_vectors)\n",
    "df_copy['target_vectors'] = df_copy['Output'].apply(sentence_to_vectors)\n",
    "\n",
    "# Convert the lists of vectors to numpy arrays\n",
    "# X = np.array(data['input_vectors'].tolist(), dtype=np.float32)\n",
    "# y = np.array(data['target_vectors'].tolist(), dtype = np.float32)\n",
    "# Pad sequences to ensure uniform length\n",
    "X = pad_sequences(df_copy['input_vectors'].tolist(), maxlen=13, dtype='float32', padding='post')\n",
    "y = pad_sequences(df_copy['target_vectors'].tolist(), maxlen=13, dtype='float32', padding='post')\n",
    "# Pad sequences to ensure uniform length\n",
    "# max_sequence_length = 30\n",
    "# X = pad_sequences(data['input_vectors'].tolist(), maxlen=max_sequence_length, dtype='float32', padding='post')\n",
    "# y = pad_sequences(data['target_vectors'].tolist(), maxlen=max_sequence_length, dtype='float32', padding='post')\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(type(y[0]))\n",
    "print(type(y))\n",
    "print(df_copy.input_vectors[0][0])\n",
    "print(df_copy.target_vectors[0][0].shape)\n",
    "print(\"This is the model vector size\", model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8641e3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input             221282\n",
       "Output            221282\n",
       "input_vectors     221282\n",
       "target_vectors    221282\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.isna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f23da29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, entry in df_copy['Input'].items():\n",
    "#     if 'morning' in entry.split():\n",
    "#         print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c926824c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(X[0][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebd3b839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.5916567   1.4283063   1.0212036  ... -1.1028557   0.2259404\n",
      "  -0.98895186]\n",
      " [ 0.01831952 -0.8715453  -0.8078755  ...  5.3653994   0.31285405\n",
      "   1.6043543 ]\n",
      " [-1.5675642  -0.4245068  -0.9991273  ... -2.7684355   2.071504\n",
      "  -0.97963536]\n",
      " ...\n",
      " [ 1.          1.          1.         ...  1.          1.\n",
      "   1.        ]\n",
      " [ 1.071439    0.6737246   0.2291265  ...  0.8988934   0.34479412\n",
      "  -0.46113047]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "data_of_ones= np.array([1] * 100, dtype=np.float32)\n",
    "for index,i in pd.Series(list(X)).items():\n",
    "    if data_of_ones in i:\n",
    "        print(i)\n",
    "        print(index)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3db9efe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SOS> then guillermo says if you go any lighter you are gonna look like an extra on 90210 <EOS>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.Input[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f493460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.071439  ,  0.6737246 ,  0.2291265 ,  0.4730969 ,  0.46964782,\n",
       "       -1.5601077 ,  0.24052994,  0.66280425,  0.7560579 ,  0.5629001 ,\n",
       "        0.9930415 ,  0.22619063, -0.12933008,  0.11528583,  0.16206235,\n",
       "       -0.1632134 , -0.3598167 , -0.7685785 , -1.1952683 ,  0.09587889,\n",
       "        0.25467503, -0.20047136, -0.93295676,  0.6219137 ,  0.99590427,\n",
       "        0.39296982,  0.10672142,  0.3047702 , -0.57695967,  0.83806294,\n",
       "        0.09376106, -1.0669171 , -0.31579226, -0.1366777 ,  0.04611401,\n",
       "       -0.6987586 ,  0.22567634, -0.23849696, -0.58052963, -0.7399004 ,\n",
       "       -0.49906853, -1.0982629 ,  0.0414573 ,  1.0530347 , -1.4203397 ,\n",
       "        0.10502852,  0.5651021 , -0.3951637 , -0.45420727,  0.6021475 ,\n",
       "       -0.07333931, -0.45426792,  0.62988496, -0.11668355, -1.488159  ,\n",
       "        1.0398401 ,  0.54428315, -0.5214992 ,  0.47743717,  0.31067878,\n",
       "       -0.9242022 , -0.8069973 ,  0.05342031,  0.7317196 , -0.4150855 ,\n",
       "       -0.10063433,  1.051501  ,  0.10644417, -1.463732  ,  0.5500406 ,\n",
       "       -1.215132  , -0.19298317, -0.63121   ,  1.5895422 ,  0.69587016,\n",
       "       -0.46677357, -1.370841  ,  0.6951841 , -1.1818871 ,  0.1589701 ,\n",
       "        0.1833699 , -0.16912623, -0.04133761,  0.05134305, -0.08565395,\n",
       "        0.2908837 , -0.00263338,  0.4040054 , -0.83824503,  0.46622646,\n",
       "       -0.3801044 , -0.42849237,  0.8023376 ,  0.3598074 , -0.25279486,\n",
       "       -0.39456782,  0.04443311,  0.8988934 ,  0.34479412, -0.46113047],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[11][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b80ffb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.071439  ,  0.6737246 ,  0.2291265 ,  0.4730969 ,  0.46964782,\n",
       "       -1.5601077 ,  0.24052994,  0.66280425,  0.7560579 ,  0.5629001 ,\n",
       "        0.9930415 ,  0.22619063, -0.12933008,  0.11528583,  0.16206235,\n",
       "       -0.1632134 , -0.3598167 , -0.7685785 , -1.1952683 ,  0.09587889,\n",
       "        0.25467503, -0.20047136, -0.93295676,  0.6219137 ,  0.99590427,\n",
       "        0.39296982,  0.10672142,  0.3047702 , -0.57695967,  0.83806294,\n",
       "        0.09376106, -1.0669171 , -0.31579226, -0.1366777 ,  0.04611401,\n",
       "       -0.6987586 ,  0.22567634, -0.23849696, -0.58052963, -0.7399004 ,\n",
       "       -0.49906853, -1.0982629 ,  0.0414573 ,  1.0530347 , -1.4203397 ,\n",
       "        0.10502852,  0.5651021 , -0.3951637 , -0.45420727,  0.6021475 ,\n",
       "       -0.07333931, -0.45426792,  0.62988496, -0.11668355, -1.488159  ,\n",
       "        1.0398401 ,  0.54428315, -0.5214992 ,  0.47743717,  0.31067878,\n",
       "       -0.9242022 , -0.8069973 ,  0.05342031,  0.7317196 , -0.4150855 ,\n",
       "       -0.10063433,  1.051501  ,  0.10644417, -1.463732  ,  0.5500406 ,\n",
       "       -1.215132  , -0.19298317, -0.63121   ,  1.5895422 ,  0.69587016,\n",
       "       -0.46677357, -1.370841  ,  0.6951841 , -1.1818871 ,  0.1589701 ,\n",
       "        0.1833699 , -0.16912623, -0.04133761,  0.05134305, -0.08565395,\n",
       "        0.2908837 , -0.00263338,  0.4040054 , -0.83824503,  0.46622646,\n",
       "       -0.3801044 , -0.42849237,  0.8023376 ,  0.3598074 , -0.25279486,\n",
       "       -0.39456782,  0.04443311,  0.8988934 ,  0.34479412, -0.46113047],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#search_word_vector(model, \"<EOS>\")\n",
    "word_vectors['<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a14f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #embed = Embedding(VOCAB_SIZE+1, 50, mask_zero=True, input_length=13)(enc_inp)\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Bidirectional, Concatenate, Dropout, Attention\n",
    "# enc_embed = X\n",
    "# enc_lstm = Bidirectional(LSTM(256, return_state=True, dropout=0.05, return_sequences = True))\n",
    "\n",
    "# encoder_outputs, forward_h, forward_c, backward_h, backward_c = enc_lstm(enc_embed)\n",
    "\n",
    "# state_h = Concatenate()([forward_h, backward_h])\n",
    "# state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "# enc_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "# #dec_inp = Input(shape=(13, ))\n",
    "# dec_embed = y\n",
    "# dec_lstm = LSTM(256, return_state=True, return_sequences=True, dropout=0.05)\n",
    "# output, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
    "\n",
    "# # attention\n",
    "# attn_layer = AttentionLayer()\n",
    "# attn_op, attn_state = attn_layer([encoder_outputs, output])\n",
    "# decoder_concat_input = Concatenate(axis=-1)([output, attn_op])\n",
    "\n",
    "\n",
    "# dec_dense = Dense(VOCAB_SIZE, activation='softmax')\n",
    "# final_output = dec_dense(decoder_concat_input)\n",
    "\n",
    "# model = Model([enc_inp, dec_inp], final_output)\n",
    "\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91472015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221282, 13, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1191ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "# encoder_input = Input(shape = (13, 100))\n",
    "# encoder = LSTM(256, return_state = True)\n",
    "# encoder_output, state_h, cell_h = encoder(encoder_input)\n",
    "# encoder_states = [state_h, cell_h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60493e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_input = Input(shape = (13,100))\n",
    "# decoder_lstm = LSTM(256, return_sequences = True, return_state = True)\n",
    "# decoder_output, _, _ = decoder_lstm(decoder_input, initial_state=encoder_states)\n",
    "# decoder_dense = Dense(100, activation = 'softmax')\n",
    "# decoder_output = decoder_dense(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c8bc06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 13, 100)]    0           []                               \n",
      "                                                                                                  \n",
      " decoder_input (InputLayer)     [(None, 13, 100)]    0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 256),        365568      ['encoder_input[0][0]']          \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(None, 13, 256),    365568      ['decoder_input[0][0]',          \n",
      "                                 (None, 256),                     'encoder_lstm[0][1]',           \n",
      "                                 (None, 256)]                     'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " decoder_dense (Dense)          (None, 13, 100)      25700       ['decoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 756,836\n",
      "Trainable params: 756,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Define the encoder\n",
    "encoder_input = Input(shape=(13, 100), name='encoder_input')\n",
    "encoder = LSTM(256, return_state=True, name='encoder_lstm')\n",
    "encoder_output, state_h, state_c = encoder(encoder_input)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder\n",
    "decoder_input = Input(shape=(13, 100), name='decoder_input')\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_output, _, _ = decoder_lstm(decoder_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(100, activation='softmax', name='decoder_dense')\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "# Build the model\n",
    "model = Model(inputs=[encoder_input, decoder_input], outputs=decoder_output)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb25205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output_data = np.zeros_like(y)\n",
    "decoder_output_data[:, :-1, :] = y[:, 1:, :]\n",
    "\n",
    "# Optionally, handle the last timestep of each sequence in decoder_output_data\n",
    "# For example, you could set it to zero, or some other appropriate value\n",
    "decoder_output_data[:, -1, :] = word_vectors['<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a597a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2767/2767 [==============================] - 200s 71ms/step - loss: 1.1905 - accuracy: 0.1898 - val_loss: 1.2022 - val_accuracy: 0.1898\n",
      "Epoch 2/10\n",
      "2767/2767 [==============================] - 190s 69ms/step - loss: 1.1905 - accuracy: 0.1894 - val_loss: 1.2022 - val_accuracy: 0.1898\n",
      "Epoch 3/10\n",
      "2767/2767 [==============================] - 206s 74ms/step - loss: 1.1905 - accuracy: 0.1901 - val_loss: 1.2022 - val_accuracy: 0.1898\n",
      "Epoch 4/10\n",
      "2767/2767 [==============================] - 215s 78ms/step - loss: 1.1905 - accuracy: 0.1902 - val_loss: 1.2023 - val_accuracy: 0.1898\n",
      "Epoch 5/10\n",
      "2767/2767 [==============================] - 191s 69ms/step - loss: 1.1905 - accuracy: 0.1897 - val_loss: 1.2023 - val_accuracy: 0.3800\n",
      "Epoch 6/10\n",
      "2767/2767 [==============================] - 192s 69ms/step - loss: 1.1905 - accuracy: 0.1902 - val_loss: 1.2022 - val_accuracy: 0.1898\n",
      "Epoch 7/10\n",
      "2767/2767 [==============================] - 190s 69ms/step - loss: 1.1905 - accuracy: 0.1899 - val_loss: 1.2022 - val_accuracy: 0.1898\n",
      "Epoch 8/10\n",
      "2767/2767 [==============================] - 196s 71ms/step - loss: 1.1905 - accuracy: 0.1904 - val_loss: 1.2022 - val_accuracy: 0.1898\n",
      "Epoch 9/10\n",
      "2767/2767 [==============================] - 192s 69ms/step - loss: 1.1905 - accuracy: 0.1895 - val_loss: 1.2022 - val_accuracy: 0.1898\n",
      "Epoch 10/10\n",
      "2767/2767 [==============================] - 189s 68ms/step - loss: 1.1905 - accuracy: 0.1900 - val_loss: 1.2022 - val_accuracy: 0.1898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x193625c6670>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "#model.save('seq2seq_model.h5')\n",
    "model.compile(optimizer='adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "model.fit([X, y], decoder_output_data, batch_size=64, epochs = 10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab0ae6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('inital_chatbot_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16fb4dd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#prediction_data_list =  preprocess_with_tags(predict_data)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m prediction_vector \u001b[38;5;241m=\u001b[39m sentence_to_vectors(predict_data)\n\u001b[1;32m----> 4\u001b[0m predict_test \u001b[38;5;241m=\u001b[39m pad_sequences(\u001b[43mprediction_vector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m(), maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m predict_test\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "predict_data = \"<SOS> Good Morning <EOS>\"\n",
    "#prediction_data_list =  preprocess_with_tags(predict_data)\n",
    "prediction_vector = sentence_to_vectors(predict_data)\n",
    "predict_test = pad_sequences(prediction_vector.tolist(), maxlen=13, dtype='float32', padding='post')\n",
    "predict_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f33914c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
