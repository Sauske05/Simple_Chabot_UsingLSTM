{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"id\": \"L1045\", \"conversation_id\": \"L1044\", \"text\": \"They do not!\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"not\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L1044\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L1044\", \"conversation_id\": \"L1044\", \"text\": \"They do to!\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"dobj\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L985\", \"conversation_id\": \"L984\", \"text\": \"I hope so.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"hope\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"so\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 1, \"dn\": []}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L984\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L984\", \"conversation_id\": \"L984\", \"text\": \"She okay?\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"She\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"okay\", \"tag\": \"RB\", \"dep\": \"ROOT\", \"dn\": [0, 2]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L925\", \"conversation_id\": \"L924\", \"text\": \"Let\\'s go.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Let\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [2, 3]}, {\"tok\": \"\\'s\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"go\", \"tag\": \"VB\", \"dep\": \"ccomp\", \"up\": 0, \"dn\": [1]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L924\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L924\", \"conversation_id\": \"L924\", \"text\": \"Wow\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Wow\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L872\", \"conversation_id\": \"L870\", \"text\": \"Okay -- you\\'re gonna need to learn how to lie.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 4, \"toks\": [{\"tok\": \"Okay\", \"tag\": \"UH\", \"dep\": \"intj\", \"up\": 4, \"dn\": []}, {\"tok\": \"--\", \"tag\": \":\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"\\'re\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"gon\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 6, 12]}, {\"tok\": \"na\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 6, \"dn\": []}, {\"tok\": \"need\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 8]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 8, \"dn\": []}, {\"tok\": \"learn\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 6, \"dn\": [7, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 11, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 11, \"dn\": []}, {\"tok\": \"lie\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 8, \"dn\": [9, 10]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": \"L871\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L871\", \"conversation_id\": \"L870\", \"text\": \"No\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"No\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": \"L870\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L870\", \"conversation_id\": \"L870\", \"text\": \"I\\'m kidding.  You know how sometimes you just become this \\\\\"persona\\\\\"?  And you don\\'t know how to quit?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 2, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"\\'m\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 2, \"dn\": []}, {\"tok\": \"kidding\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 3]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 2, \"dn\": [4]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 3, \"dn\": []}]}, {\"rt\": 1, \"toks\": [{\"tok\": \"You\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 6, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 3, \"dn\": []}, {\"tok\": \"sometimes\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": [2]}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 6, \"dn\": []}, {\"tok\": \"just\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": []}, {\"tok\": \"become\", \"tag\": \"VBP\", \"dep\": \"ccomp\", \"up\": 1, \"dn\": [3, 4, 5, 9]}, {\"tok\": \"this\", \"tag\": \"DT\", \"dep\": \"det\", \"up\": 9, \"dn\": []}, {\"tok\": \"\\\\\"\", \"tag\": \"``\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"persona\", \"tag\": \"NN\", \"dep\": \"attr\", \"up\": 6, \"dn\": [7, 8, 10]}, {\"tok\": \"\\\\\"\", \"tag\": \"\\'\\'\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": [12]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 11, \"dn\": []}]}, {\"rt\": 4, \"toks\": [{\"tok\": \"And\", \"tag\": \"CC\", \"dep\": \"cc\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"n\\'t\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 4, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 7, 8]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 7, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 7, \"dn\": []}, {\"tok\": \"quit\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 6]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L869\", \"conversation_id\": \"L866\", \"text\": \"Like my fear of wearing pastels?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Like\", \"tag\": \"IN\", \"dep\": \"ROOT\", \"dn\": [2, 6]}, {\"tok\": \"my\", \"tag\": \"PRP$\", \"dep\": \"poss\", \"up\": 2, \"dn\": []}, {\"tok\": \"fear\", \"tag\": \"NN\", \"dep\": \"pobj\", \"up\": 0, \"dn\": [1, 3]}, {\"tok\": \"of\", \"tag\": \"IN\", \"dep\": \"prep\", \"up\": 2, \"dn\": [4]}, {\"tok\": \"wearing\", \"tag\": \"VBG\", \"dep\": \"pcomp\", \"up\": 3, \"dn\": [5]}, {\"tok\": \"pastels\", \"tag\": \"NNS\", \"dep\": \"dobj\", \"up\": 4, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L868\", \"timestamp\": null, \"vectors\": []}\\n'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import json\n",
    "\n",
    "corpus_name = \"movie-corpus\"\n",
    "corpus = os.path.join(\"data\", corpus_name)\n",
    "\n",
    "def printLines(file, n=10):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "printLines(os.path.join(corpus, \"utterances.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits each line of the file to create lines and conversations\n",
    "def loadLinesAndConversations(fileName, n):\n",
    "    lines = {}\n",
    "    conversations = {}\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            lineJson = json.loads(line)\n",
    "            # Extract fields for line object\n",
    "            lineObj = {}\n",
    "            lineObj[\"lineID\"] = lineJson[\"id\"] #example : L1045\n",
    "            lineObj[\"characterID\"] = lineJson[\"speaker\"] # example : u1, u2\n",
    "            lineObj[\"text\"] = lineJson[\"text\"] #These are the conversations\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "\n",
    "            # Extract fields for conversation object\n",
    "            if lineJson[\"conversation_id\"] not in conversations:\n",
    "                convObj = {}\n",
    "                convObj[\"conversationID\"] = lineJson[\"conversation_id\"]\n",
    "                convObj[\"movieID\"] = lineJson[\"meta\"][\"movie_id\"]\n",
    "                convObj[\"lines\"] = [lineObj]\n",
    "            else:\n",
    "                convObj = conversations[lineJson[\"conversation_id\"]]\n",
    "                convObj[\"lines\"].insert(0, lineObj)\n",
    "            conversations[convObj[\"conversationID\"]] = convObj\n",
    "    first_n_items = dict(itertools.islice(lines.items(), n))\n",
    "    print(first_n_items)\n",
    "    print(\"Line dictionary ends!! \\n\")\n",
    "    second_n_items = dict(itertools.islice(conversations.items(), n))\n",
    "    print(second_n_items)\n",
    "\n",
    "    return lines, conversations\n",
    "\n",
    "\n",
    "# Extracts pairs of sentences from conversations\n",
    "def extractSentencePairs(conversations):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations.values():\n",
    "        # Iterate over all the lines of the conversation\n",
    "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # Filter wrong samples (if one of the lists is empty)\n",
    "            if inputLine and targetLine:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus into lines and conversations...\n",
      "{'L1045': {'lineID': 'L1045', 'characterID': 'u0', 'text': 'They do not!'}, 'L1044': {'lineID': 'L1044', 'characterID': 'u2', 'text': 'They do to!'}, 'L985': {'lineID': 'L985', 'characterID': 'u0', 'text': 'I hope so.'}, 'L984': {'lineID': 'L984', 'characterID': 'u2', 'text': 'She okay?'}, 'L925': {'lineID': 'L925', 'characterID': 'u0', 'text': \"Let's go.\"}, 'L924': {'lineID': 'L924', 'characterID': 'u2', 'text': 'Wow'}, 'L872': {'lineID': 'L872', 'characterID': 'u0', 'text': \"Okay -- you're gonna need to learn how to lie.\"}, 'L871': {'lineID': 'L871', 'characterID': 'u2', 'text': 'No'}, 'L870': {'lineID': 'L870', 'characterID': 'u0', 'text': 'I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?'}, 'L869': {'lineID': 'L869', 'characterID': 'u0', 'text': 'Like my fear of wearing pastels?'}}\n",
      "Line dictionary ends!! \n",
      "\n",
      "{'L1044': {'conversationID': 'L1044', 'movieID': 'm0', 'lines': [{'lineID': 'L1044', 'characterID': 'u2', 'text': 'They do to!'}, {'lineID': 'L1045', 'characterID': 'u0', 'text': 'They do not!'}]}, 'L984': {'conversationID': 'L984', 'movieID': 'm0', 'lines': [{'lineID': 'L984', 'characterID': 'u2', 'text': 'She okay?'}, {'lineID': 'L985', 'characterID': 'u0', 'text': 'I hope so.'}]}, 'L924': {'conversationID': 'L924', 'movieID': 'm0', 'lines': [{'lineID': 'L924', 'characterID': 'u2', 'text': 'Wow'}, {'lineID': 'L925', 'characterID': 'u0', 'text': \"Let's go.\"}]}, 'L870': {'conversationID': 'L870', 'movieID': 'm0', 'lines': [{'lineID': 'L870', 'characterID': 'u0', 'text': 'I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?'}, {'lineID': 'L871', 'characterID': 'u2', 'text': 'No'}, {'lineID': 'L872', 'characterID': 'u0', 'text': \"Okay -- you're gonna need to learn how to lie.\"}]}, 'L866': {'conversationID': 'L866', 'movieID': 'm0', 'lines': [{'lineID': 'L866', 'characterID': 'u2', 'text': \"I figured you'd get to the good stuff eventually.\"}, {'lineID': 'L867', 'characterID': 'u0', 'text': 'What good stuff?'}, {'lineID': 'L868', 'characterID': 'u2', 'text': 'The \"real you\".'}, {'lineID': 'L869', 'characterID': 'u0', 'text': 'Like my fear of wearing pastels?'}]}, 'L862': {'conversationID': 'L862', 'movieID': 'm0', 'lines': [{'lineID': 'L862', 'characterID': 'u0', 'text': 'do you listen to this crap?'}, {'lineID': 'L863', 'characterID': 'u2', 'text': 'What crap?'}, {'lineID': 'L864', 'characterID': 'u0', 'text': \"Me.  This endless ...blonde babble. I'm like, boring myself.\"}, {'lineID': 'L865', 'characterID': 'u2', 'text': 'Thank God!  If I had to hear one more story about your coiffure...'}]}, 'L860': {'conversationID': 'L860', 'movieID': 'm0', 'lines': [{'lineID': 'L860', 'characterID': 'u0', 'text': 'Then Guillermo says, \"If you go any lighter, you\\'re gonna look like an extra on 90210.\"'}, {'lineID': 'L861', 'characterID': 'u2', 'text': 'No...'}]}, 'L696': {'conversationID': 'L696', 'movieID': 'm0', 'lines': [{'lineID': 'L696', 'characterID': 'u0', 'text': 'Well, no...'}, {'lineID': 'L697', 'characterID': 'u2', 'text': \"Then that's all you had to say.\"}, {'lineID': 'L698', 'characterID': 'u0', 'text': 'But'}, {'lineID': 'L699', 'characterID': 'u2', 'text': 'You always been this selfish?'}]}, 'L693': {'conversationID': 'L693', 'movieID': 'm0', 'lines': [{'lineID': 'L693', 'characterID': 'u2', 'text': 'I looked for you back at the party, but you always seemed to be \"occupied\".'}, {'lineID': 'L694', 'characterID': 'u0', 'text': 'I was?'}, {'lineID': 'L695', 'characterID': 'u2', 'text': \"You never wanted to go out with 'me, did you?\"}]}, 'L662': {'conversationID': 'L662', 'movieID': 'm0', 'lines': [{'lineID': 'L662', 'characterID': 'u2', 'text': 'Have fun tonight?'}, {'lineID': 'L663', 'characterID': 'u0', 'text': 'Tons'}]}}\n",
      "\n",
      "Writing newly formatted file...\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import itertools\n",
    "# Define path to new file\n",
    "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
    "\n",
    "delimiter = ','\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "# Initialize lines dict and conversations dict\n",
    "lines = {}\n",
    "conversations = {}\n",
    "# Load lines and conversations\n",
    "print(\"\\nProcessing corpus into lines and conversations...\")\n",
    "lines, conversations = loadLinesAndConversations(os.path.join(corpus, \"utterances.jsonl\"), 10)\n",
    "\n",
    "# Write new csv file\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "# with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "#     writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "#     for pair in extractSentencePairs(conversations):\n",
    "#         writer.writerow(pair)\n",
    "\n",
    "# # Print a sample of lines\n",
    "# print(\"\\nSample lines from file:\")\n",
    "# printLines(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\arun\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\arun\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\arun\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\arun\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\arun\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\arun\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/movie-corpus/formatted_movie_lines.txt\")\n",
    "# Define the text to add\n",
    "import re\n",
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
    "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
    "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
    "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
    "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
    "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
    "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
    "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
    "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
    "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
    "    return txt\n",
    "df['Input'] = df['Input'].apply(lambda x: clean_text(x))\n",
    "df['Output'] = df['Output'].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;SOS&gt; they do to &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; they do not &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SOS&gt; she okay &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; i hope so &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;SOS&gt; wow &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; lets go &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;SOS&gt; i am kidding  you know how sometimes you...</td>\n",
       "      <td>&lt;SOS&gt; no &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;SOS&gt; no &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; okay  you are gonna need to learn how to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221277</th>\n",
       "      <td>&lt;SOS&gt; and i assure you you do not in fact i wo...</td>\n",
       "      <td>&lt;SOS&gt; so far only their scouts but we have had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221278</th>\n",
       "      <td>&lt;SOS&gt; your orders mr vereker &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; i am to take the sikali with the main co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221279</th>\n",
       "      <td>&lt;SOS&gt; i am to take the sikali with the main co...</td>\n",
       "      <td>&lt;SOS&gt; lord chelmsford seems to want me to stay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221280</th>\n",
       "      <td>&lt;SOS&gt; lord chelmsford seems to want me to stay...</td>\n",
       "      <td>&lt;SOS&gt; i think chelmsford wants a good man on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221281</th>\n",
       "      <td>&lt;SOS&gt; colonel durnford william vereker i hear ...</td>\n",
       "      <td>&lt;SOS&gt; good ones yes mr vereker gentlemen who c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221282 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Input  \\\n",
       "0                                  <SOS> they do to <EOS>   \n",
       "1                                    <SOS> she okay <EOS>   \n",
       "2                                         <SOS> wow <EOS>   \n",
       "3       <SOS> i am kidding  you know how sometimes you...   \n",
       "4                                          <SOS> no <EOS>   \n",
       "...                                                   ...   \n",
       "221277  <SOS> and i assure you you do not in fact i wo...   \n",
       "221278                 <SOS> your orders mr vereker <EOS>   \n",
       "221279  <SOS> i am to take the sikali with the main co...   \n",
       "221280  <SOS> lord chelmsford seems to want me to stay...   \n",
       "221281  <SOS> colonel durnford william vereker i hear ...   \n",
       "\n",
       "                                                   Output  \n",
       "0                                 <SOS> they do not <EOS>  \n",
       "1                                   <SOS> i hope so <EOS>  \n",
       "2                                     <SOS> lets go <EOS>  \n",
       "3                                          <SOS> no <EOS>  \n",
       "4       <SOS> okay  you are gonna need to learn how to...  \n",
       "...                                                   ...  \n",
       "221277  <SOS> so far only their scouts but we have had...  \n",
       "221278  <SOS> i am to take the sikali with the main co...  \n",
       "221279  <SOS> lord chelmsford seems to want me to stay...  \n",
       "221280  <SOS> i think chelmsford wants a good man on t...  \n",
       "221281  <SOS> good ones yes mr vereker gentlemen who c...  \n",
       "\n",
       "[221282 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_text = '<SOS> '\n",
    "end_text = ' <EOS>'\n",
    "\n",
    "# Add text to the specific column 'A'\n",
    "df['Input'] = df['Input'].apply(lambda x: f\"{start_text }{x}{ end_text}\")\n",
    "df['Output'] = df['Output'].apply(lambda x: f\"{start_text }{x}{ end_text}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221282 entries, 0 to 221281\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Input   221282 non-null  object\n",
      " 1   Output  221282 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;SOS&gt; they do to &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; they do not &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;SOS&gt; she okay &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; i hope so &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;SOS&gt; wow &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; lets go &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;SOS&gt; no &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; okay  you are gonna need to learn how to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;SOS&gt; i figured you would get to the good stuf...</td>\n",
       "      <td>&lt;SOS&gt; what good stuff &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98723</th>\n",
       "      <td>221265</td>\n",
       "      <td>&lt;SOS&gt; stuart &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; yes &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98724</th>\n",
       "      <td>221266</td>\n",
       "      <td>&lt;SOS&gt; yes &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; how quickly can you move your artillery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98725</th>\n",
       "      <td>221269</td>\n",
       "      <td>&lt;SOS&gt; well fed or hungry pulleine wants them i...</td>\n",
       "      <td>&lt;SOS&gt; right  bombardier to me please &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98726</th>\n",
       "      <td>221271</td>\n",
       "      <td>&lt;SOS&gt; do you think she might be interested in ...</td>\n",
       "      <td>&lt;SOS&gt; which one &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98727</th>\n",
       "      <td>221272</td>\n",
       "      <td>&lt;SOS&gt; which one &lt;EOS&gt;</td>\n",
       "      <td>&lt;SOS&gt; well that one the one who keeps looking ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98728 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                              Input  \\\n",
       "0           0                             <SOS> they do to <EOS>   \n",
       "1           1                               <SOS> she okay <EOS>   \n",
       "2           2                                    <SOS> wow <EOS>   \n",
       "3           4                                     <SOS> no <EOS>   \n",
       "4           5  <SOS> i figured you would get to the good stuf...   \n",
       "...       ...                                                ...   \n",
       "98723  221265                                 <SOS> stuart <EOS>   \n",
       "98724  221266                                    <SOS> yes <EOS>   \n",
       "98725  221269  <SOS> well fed or hungry pulleine wants them i...   \n",
       "98726  221271  <SOS> do you think she might be interested in ...   \n",
       "98727  221272                              <SOS> which one <EOS>   \n",
       "\n",
       "                                                  Output  \n",
       "0                                <SOS> they do not <EOS>  \n",
       "1                                  <SOS> i hope so <EOS>  \n",
       "2                                    <SOS> lets go <EOS>  \n",
       "3      <SOS> okay  you are gonna need to learn how to...  \n",
       "4                            <SOS> what good stuff <EOS>  \n",
       "...                                                  ...  \n",
       "98723                                    <SOS> yes <EOS>  \n",
       "98724  <SOS> how quickly can you move your artillery ...  \n",
       "98725         <SOS> right  bombardier to me please <EOS>  \n",
       "98726                              <SOS> which one <EOS>  \n",
       "98727  <SOS> well that one the one who keeps looking ...  \n",
       "\n",
       "[98728 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where the length of split words in each column is <= 10\n",
    "filtered_df = df_copy[df_copy.apply(lambda row: all(len(col.split()) <= 12 for col in row), axis=1)].reset_index()\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SOS>', 'they', 'do', 'to', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess while preserving <SOS> and <EOS>\n",
    "def preprocess_with_tags(text):\n",
    "    words = text.split()\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        if word in [\"<SOS>\", \"<EOS>\"]:\n",
    "            processed_words.append(word)\n",
    "        else:\n",
    "            processed_words.extend(gensim.utils.simple_preprocess(word))\n",
    "    return processed_words\n",
    "\n",
    "# Sample text\n",
    "review_text = \"<SOS> they do to <EOS>\"\n",
    "\n",
    "# Preprocess the text\n",
    "processed_text = preprocess_with_tags(review_text)\n",
    "\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    <SOS> they do to <EOS>\n",
       "1                                      <SOS> she okay <EOS>\n",
       "2                                           <SOS> wow <EOS>\n",
       "3                                            <SOS> no <EOS>\n",
       "4         <SOS> i figured you would get to the good stuf...\n",
       "                                ...                        \n",
       "197451                                      <SOS> yes <EOS>\n",
       "197452    <SOS> how quickly can you move your artillery ...\n",
       "197453           <SOS> right  bombardier to me please <EOS>\n",
       "197454                                <SOS> which one <EOS>\n",
       "197455    <SOS> well that one the one who keeps looking ...\n",
       "Length: 197456, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_column = pd.concat([filtered_df['Input'], filtered_df['Output']], ignore_index=True)\n",
    "new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "max = 0\n",
    "for i in range(len(new_column)):\n",
    "    count = len(new_column[i].split())\n",
    "    if count > max:\n",
    "        max = count\n",
    "    count = 0\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = new_column.apply(lambda x: preprocess_with_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<SOS>', 'say', 'do', 'what', 'you', 'wanna', 'do', '<EOS>']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text.loc[192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 9525\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=4,\n",
    "    workers=4,\n",
    ")\n",
    "model.build_vocab(review_text, progress_per=1000)\n",
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "vocab_size = len(model.wv.key_to_index)\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for the word 'morning':\n",
      "[-0.12011132  0.384622   -0.15799433  0.3210568   0.49736395 -0.5900213\n",
      " -0.08336844  0.87894773 -1.2149109   0.4858342  -0.21717048 -1.1692823\n",
      " -0.62061596  1.0418295  -0.25395197 -0.5788785   0.02252335  0.19325288\n",
      " -0.0026791  -0.8923486   0.67126286  0.09370332  0.9022529  -0.23918276\n",
      "  0.87901676 -0.10139964  0.2430153   0.3173359  -0.63683474 -0.19720043\n",
      "  0.7854393   0.24688905  0.03222169  0.25488296 -0.04853523  0.07995187\n",
      "  0.71817917 -1.0489568  -0.37199947 -0.8017701  -0.3987603  -0.31087512\n",
      " -0.8043076   0.18803518 -0.07598886  1.2383559   0.3982284   0.815971\n",
      "  0.44939354 -0.62986994  0.27540803  0.66275     0.5839314  -0.54130524\n",
      " -0.80799675 -0.41315117  0.42124674 -0.4756348  -0.65298754  0.37842572\n",
      "  0.561582   -0.20618445 -0.6149973   0.5399425  -0.78569937 -0.9815398\n",
      "  0.2246714   0.7103429  -0.1590571   0.13897036  0.96357584 -0.42784545\n",
      "  0.01243685  0.11778596  1.141583    1.2254637  -0.34182286  0.2271248\n",
      " -0.16988152  0.18186165 -0.24793206 -0.949814   -0.31527215 -0.01149646\n",
      " -0.08206926 -0.14344934  1.0252699   0.00916795  0.40633202 -0.43455225\n",
      "  0.33796504  0.2713897   0.11818806 -0.05798139 -0.6862908   1.403452\n",
      " -0.08951648 -0.5942184  -0.81693125  0.15370907]\n"
     ]
    }
   ],
   "source": [
    "def search_word_vector(model, word):\n",
    "    if word in model.wv.key_to_index:\n",
    "        vector = model.wv[word]\n",
    "        print(f\"Vector for the word '{word}':\\n{vector}\")\n",
    "    else:\n",
    "        print(f\"The word '{word}' is not in the vocabulary.\")\n",
    "\n",
    "search_word_vector(model, \"morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('afternoon', 0.8214861750602722),\n",
       " ('evening', 0.7791115641593933),\n",
       " ('weekend', 0.7235478162765503),\n",
       " ('night', 0.7098230123519897),\n",
       " ('content', 0.6578639149665833),\n",
       " ('luck', 0.6557112336158752),\n",
       " ('day', 0.6201649308204651),\n",
       " ('year', 0.617409348487854),\n",
       " ('drugstore', 0.6165878176689148),\n",
       " ('week', 0.6120112538337708)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"morning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<SOS>': array([ 1.1115055 , -0.2854384 ,  0.2021238 , -0.6217669 , -0.6933692 ,\n",
      "       -0.8168397 , -0.16299292,  0.740368  , -0.12952244,  0.18133585,\n",
      "        0.6142206 , -0.28838816,  0.12359715,  0.22400317,  0.9092182 ,\n",
      "       -0.42435244, -0.42218113, -0.36179215,  0.31091332, -1.3080089 ,\n",
      "        1.4772648 , -0.05265462, -0.7668279 ,  0.34306273,  0.3530216 ,\n",
      "        0.1884358 ,  0.67026126,  1.0856019 , -0.7882152 ,  0.18373744,\n",
      "       -0.68636966,  0.31173658,  0.27774388, -0.22424884, -0.23144087,\n",
      "        0.3955155 ,  1.3653605 , -0.28003174, -0.46463773, -1.3446448 ,\n",
      "       -1.5426947 ,  0.05352983, -0.25557604, -0.6083303 , -0.9108917 ,\n",
      "        0.03340705, -0.37861347,  0.16701734,  0.03465249,  0.5073217 ,\n",
      "       -0.22328208, -0.64848864, -1.4312875 , -0.7043642 ,  0.6696109 ,\n",
      "       -0.6709416 ,  1.0156107 , -1.5408536 , -0.8795676 , -0.7562373 ,\n",
      "       -0.3392753 ,  0.5410064 , -0.44258037,  0.8056419 , -1.1505798 ,\n",
      "        0.30592555,  0.01169863,  0.05931721, -0.4931133 , -0.8664341 ,\n",
      "        0.7084423 ,  0.35158813, -0.27917096, -0.4043178 ,  0.11320221,\n",
      "        0.4076801 ,  0.6073329 ,  0.4200324 , -0.9545927 ,  0.91295147,\n",
      "        0.4812382 ,  0.55912167,  0.34411523,  0.5469762 , -0.6152986 ,\n",
      "        0.43539667, -0.87582076,  1.3621414 , -0.23975752, -0.64424187,\n",
      "       -0.4249226 ,  1.3654376 , -0.31440404,  0.7957029 ,  0.26666915,\n",
      "       -0.47201702, -1.081498  , -0.39041847, -0.66674656, -0.01741816],\n",
      "      dtype=float32), '<EOS>': array([ 7.1232445e-03,  4.4554949e-01,  3.7690368e-01, -4.2510968e-01,\n",
      "       -6.3162677e-02, -1.0832033e+00, -1.4982663e-01,  1.0572751e+00,\n",
      "       -2.6368970e-01,  4.2884088e-01,  3.8778067e-01, -5.3223741e-01,\n",
      "       -5.8695126e-01,  7.5576991e-02,  1.0019891e+00, -1.1293761e+00,\n",
      "        5.5103421e-01,  2.3700052e-01, -2.7653959e-01, -4.1326508e-01,\n",
      "        8.5184824e-01,  4.1823614e-01, -7.0902514e-01, -1.7853299e-01,\n",
      "        9.2162317e-01,  2.3139931e-01,  8.3592999e-01, -5.5326456e-01,\n",
      "       -3.5242233e-01,  1.1215941e+00,  1.8204829e-01,  5.0687718e-01,\n",
      "       -1.7798297e-01, -2.9836002e-01, -2.6072666e-01, -1.2845150e-01,\n",
      "        4.0059906e-01,  9.3096095e-01, -3.5549349e-01, -1.0705001e+00,\n",
      "        4.8098990e-04,  2.1475683e-01,  3.0156589e-01, -1.9146395e-01,\n",
      "       -7.5872326e-01,  9.2267644e-01,  2.1030590e-01, -9.4445840e-02,\n",
      "        5.9331138e-02, -4.0925059e-02,  6.5558022e-01, -5.1653814e-01,\n",
      "       -1.1268978e+00, -8.2018882e-01, -2.3610462e-01, -1.1419895e+00,\n",
      "        1.8033245e-01,  3.3222854e-01, -8.6730105e-01, -7.8357351e-01,\n",
      "        4.1095048e-01, -2.2926703e-01, -1.1944391e+00,  4.7978270e-01,\n",
      "       -1.0376636e+00,  3.4096703e-01,  4.9426258e-01,  4.2404732e-01,\n",
      "        3.5619894e-01,  3.5121396e-01, -3.7400657e-01,  1.5292731e-01,\n",
      "       -2.3336630e-01,  7.9913360e-01, -1.2654482e-01,  1.9880483e-01,\n",
      "        2.8512827e-01, -1.0601563e+00, -3.8999107e-01,  1.0864024e+00,\n",
      "       -5.0036184e-02,  2.5137520e-01, -5.9916276e-02,  4.4533837e-01,\n",
      "       -2.5500202e-01,  3.3373916e-01, -1.4753270e+00,  8.2241720e-01,\n",
      "       -4.1472983e-02, -8.0543905e-01,  5.1863253e-01,  2.3979120e-01,\n",
      "       -5.3467620e-02,  8.1693995e-01, -1.2625312e+00,  1.2463118e-01,\n",
      "       -9.2786938e-02, -2.4875499e-01,  2.3874956e-01, -1.0213863e-01],\n",
      "      dtype=float32), 'you': array([ 1.4492162 ,  0.00407399, -0.7769935 , -1.3192934 ,  0.40275913,\n",
      "       -0.9374464 , -0.98748946,  1.0979446 ,  0.19807972,  0.03746297,\n",
      "        1.055508  , -0.71286565,  1.4284352 ,  0.27007622,  0.85270137,\n",
      "       -1.0334773 ,  2.262729  ,  1.4335912 , -0.8365085 , -1.2257813 ,\n",
      "        0.7226206 , -0.6960964 , -1.3437232 ,  0.45489308,  0.900161  ,\n",
      "       -1.4386374 ,  1.8736764 ,  0.68972623, -0.33428454,  0.48862436,\n",
      "        0.0628304 ,  0.8092165 , -0.7081446 , -0.75950456, -0.6999001 ,\n",
      "        0.3728721 ,  0.5028893 ,  0.8180833 , -0.14696465,  0.44975764,\n",
      "       -1.0017365 ,  1.499653  ,  1.2123259 ,  0.56141126, -0.20198779,\n",
      "        0.10888115,  0.95029515, -0.23048486, -1.1776259 ,  0.56919897,\n",
      "        0.2874446 ,  0.7429478 , -0.7519368 , -0.68076015, -0.8363578 ,\n",
      "       -0.46527818,  1.0076047 , -0.45426688, -1.9217904 , -1.5532273 ,\n",
      "       -1.1845418 , -0.37295383,  0.03590313,  0.6165238 , -1.3106815 ,\n",
      "        1.2807002 ,  0.7725385 , -0.12158668,  1.1394639 , -0.89617074,\n",
      "        1.2334442 , -0.2921279 , -0.47983572,  1.1083485 ,  0.6657625 ,\n",
      "        0.20777084,  2.0016577 ,  0.79124516, -0.39617008,  0.40143508,\n",
      "       -0.14556912,  0.35925654, -0.5817179 ,  0.3184119 , -0.33423758,\n",
      "        0.1992429 , -1.3691024 , -0.9215477 ,  1.8352205 ,  0.06247734,\n",
      "        0.38359973,  0.9518421 ,  0.68322915,  0.1950358 ,  0.6103266 ,\n",
      "        0.6347268 , -1.1096172 , -0.2704252 , -0.8043025 , -0.37967026],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary\n",
    "word_vectors = {}\n",
    "\n",
    "# Iterate through the vocabulary\n",
    "for word in model.wv.index_to_key:\n",
    "    # Add the word and its vector to the dictionary\n",
    "    #print(type( model.wv[word]))\n",
    "    word_vectors[word] = model.wv[word]\n",
    "\n",
    "# Now word_vectors is a dictionary with words as keys and vectors as values\n",
    "top_three_word_vectors = dict(list(word_vectors.items())[:3])\n",
    "print(top_three_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "key1 = '<OUT>'\n",
    "value1 = [1] * 100\n",
    "key2 = '<PAD>'\n",
    "value2 = [0] * 100\n",
    "word_vectors[key1] = np.array(value1, dtype=np.float32)\n",
    "word_vectors[key2] = np.array(value2, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OUT>\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "<PAD>\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for key, values in word_vectors.items():\n",
    "    if key == '<OUT>' or key == '<PAD>':\n",
    "        print(key)\n",
    "        print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "#from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the pre-trained Word2Vec model\n",
    "#model = Word2Vec.load(\"./data/movie-corpus/word2vec.model\")\n",
    "\n",
    "# Convert sentences to sequences of vectors\n",
    "\n",
    "def sentence_to_vectors(sentence):\n",
    "    gensim_sentences_list = preprocess_with_tags(sentence)\n",
    "    #vectors = [model.wv[word] for word in gensim_sentences_list if word in model.wv]\n",
    "#     vectors = [word_vectors[word] for word in word_vectors.keys() if word in wor]\n",
    "    global vectors\n",
    "    vectors= []\n",
    "    for word in gensim_sentences_list:\n",
    "        if word in word_vectors.keys():\n",
    "            vectors.append(word_vectors[word])\n",
    "        else:\n",
    "            vectors.append(word_vectors['<OUT>'])\n",
    "        \n",
    "        \n",
    "#     for word in sentence.lower.split():\n",
    "#         if word.contains(\"'\")\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['input_vectors'] = filtered_df['Input'].apply(sentence_to_vectors)\n",
    "filtered_df['target_vectors'] = filtered_df['Output'].apply(sentence_to_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [[1.1115055, -0.2854384, 0.2021238, -0.6217669...\n",
       "1        [[1.1115055, -0.2854384, 0.2021238, -0.6217669...\n",
       "2        [[1.1115055, -0.2854384, 0.2021238, -0.6217669...\n",
       "3        [[1.1115055, -0.2854384, 0.2021238, -0.6217669...\n",
       "4        [[1.1115055, -0.2854384, 0.2021238, -0.6217669...\n",
       "                               ...                        \n",
       "98723    [[1.1115055, -0.2854384, 0.2021238, -0.6217669...\n",
       "98724    [[1.1115055, -0.2854384, 0.2021238, -0.6217669...\n",
       "98725    [[1.1115055, -0.2854384, 0.2021238, -0.6217669...\n",
       "98726    [[1.1115055, -0.2854384, 0.2021238, -0.6217669...\n",
       "98727    [[1.1115055, -0.2854384, 0.2021238, -0.6217669...\n",
       "Name: input_vectors, Length: 98728, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['input_vectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_vectors = df_copy['input_vectors'].tolist()\n",
    "#target_vectors = df_copy['target_vectors'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_fn(data):\n",
    "    for i in data:\n",
    "        while len(i) != 12:\n",
    "            i.append(word_vectors['<PAD>'])\n",
    "padding_fn(filtered_df['input_vectors'])\n",
    "padding_fn(filtered_df['target_vectors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98728, 12, 100])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor(filtered_df['input_vectors'], dtype = torch.float32)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98728, 12, 100])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(filtered_df['target_vectors'], dtype = torch.float32)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X[:78982]\n",
    "y_train= y[:78982]\n",
    "X_test = X[78983:]\n",
    "y_test = y[78983:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train: torch.Size([78982, 12, 100])\n",
      "Shape of y train: torch.Size([78982, 12, 100])\n",
      "Shape of X test: torch.Size([19745, 12, 100])\n",
      "Shape of y test: torch.Size([19745, 12, 100])\n"
     ]
    }
   ],
   "source": [
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "X_test_shape = X_test.shape\n",
    "y_test_shape = y_test.shape\n",
    "print(f\"Shape of X train: {X_train_shape}\")\n",
    "print(f\"Shape of y train: {y_train_shape}\")\n",
    "print(f\"Shape of X test: {X_test_shape}\")\n",
    "print(f\"Shape of y test: {y_test_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        return hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim + hidden_dim, hidden_dim)\n",
    "        self.fc_out = nn.Linear(embedding_dim + hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell, context):\n",
    "        # input = [batch size]\n",
    "        # hidden = [1, batch size, hidden dim]\n",
    "        # cell = [1, batch size, hidden dim]\n",
    "        # context = [1, batch size, hidden dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        \n",
    "        emb_con = torch.cat((embedded, context), dim=2)\n",
    "        # emb_con = [1, batch size, embedding dim + hidden dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(emb_con, (hidden, cell))\n",
    "        # output = [1, batch size, hidden dim]\n",
    "        # hidden = [1, batch size, hidden dim]\n",
    "        # cell = [1, batch size, hidden dim]\n",
    "        \n",
    "        output = torch.cat(\n",
    "            (embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), dim=1\n",
    "        )\n",
    "        # output = [batch size, embedding dim + hidden dim * 2]\n",
    "        \n",
    "        prediction = self.fc_out(output)\n",
    "        # prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # last hidden state of the encoder is the context\n",
    "        context = self.encoder(src)\n",
    "        # context = [n layers * n directions, batch size, hidden dim]\n",
    "        # context also used as the initial hidden state of the decoder\n",
    "        hidden = context\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden state and the context state\n",
    "            # receive output tensor (predictions) and new hidden state\n",
    "            output, hidden = self.decoder(input, hidden, context)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [1, batch size, hidden dim]\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "output_dim = 100\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    decoder_dropout,\n",
    ")\n",
    "\n",
    "model_0 = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(100, 256)\n",
       "    (rnn): LSTM(256, 512)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(100, 256)\n",
       "    (rnn): LSTM(768, 512)\n",
       "    (fc_out): Linear(in_features=1280, out_features=100, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "\n",
    "\n",
    "model_0.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,381,796 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=word_vectors['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 100\n",
    "\n",
    "# Put data to target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "# Build training and evaluation loop\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model_0.train()\n",
    "\n",
    "    # 1. Forward pass (model outputs raw logits)\n",
    "    y_logits = model_0(X_train).squeeze() # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device \n",
    "    y_pred = torch.round(torch.sigmoid(y_logits)) # turn logits -> pred probs -> pred labls\n",
    "  \n",
    "    # 2. Calculate loss/accuracy\n",
    "    # loss = loss_fn(torch.sigmoid(y_logits), # Using nn.BCELoss you need torch.sigmoid()\n",
    "    #                y_train) \n",
    "    loss = loss_fn(y_logits, # Using nn.BCEWithLogitsLoss works with raw logits\n",
    "                   y_train) \n",
    "    acc = accuracy_fn(y_true=y_train, \n",
    "                      y_pred=y_pred) \n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 1. Forward pass\n",
    "        test_logits = model_0(X_test).squeeze() \n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "        # 2. Caculate loss/accuracy\n",
    "        test_loss = loss_fn(test_logits,\n",
    "                            y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                               y_pred=test_pred)\n",
    "\n",
    "    # Print out what's happening every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
