{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a1162c7-7829-444d-a38d-03faa46f966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Arun\\Machine Learning\\VirtualEnvProjects\\PyTorch\\torch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "import datasets\n",
    "import torchtext\n",
    "#import tqdm\n",
    "import evaluate\n",
    "\n",
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c16c37-6a37-4ec6-be9e-afc49d3693f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"id\": \"L1045\", \"conversation_id\": \"L1044\", \"text\": \"They do not!\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"not\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L1044\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L1044\", \"conversation_id\": \"L1044\", \"text\": \"They do to!\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"dobj\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L985\", \"conversation_id\": \"L984\", \"text\": \"I hope so.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"hope\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"so\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 1, \"dn\": []}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L984\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L984\", \"conversation_id\": \"L984\", \"text\": \"She okay?\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"She\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"okay\", \"tag\": \"RB\", \"dep\": \"ROOT\", \"dn\": [0, 2]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L925\", \"conversation_id\": \"L924\", \"text\": \"Let\\'s go.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Let\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [2, 3]}, {\"tok\": \"\\'s\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"go\", \"tag\": \"VB\", \"dep\": \"ccomp\", \"up\": 0, \"dn\": [1]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L924\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L924\", \"conversation_id\": \"L924\", \"text\": \"Wow\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Wow\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L872\", \"conversation_id\": \"L870\", \"text\": \"Okay -- you\\'re gonna need to learn how to lie.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 4, \"toks\": [{\"tok\": \"Okay\", \"tag\": \"UH\", \"dep\": \"intj\", \"up\": 4, \"dn\": []}, {\"tok\": \"--\", \"tag\": \":\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"\\'re\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"gon\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 6, 12]}, {\"tok\": \"na\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 6, \"dn\": []}, {\"tok\": \"need\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 8]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 8, \"dn\": []}, {\"tok\": \"learn\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 6, \"dn\": [7, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 11, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 11, \"dn\": []}, {\"tok\": \"lie\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 8, \"dn\": [9, 10]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": \"L871\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L871\", \"conversation_id\": \"L870\", \"text\": \"No\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"No\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": \"L870\", \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L870\", \"conversation_id\": \"L870\", \"text\": \"I\\'m kidding.  You know how sometimes you just become this \\\\\"persona\\\\\"?  And you don\\'t know how to quit?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 2, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"\\'m\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 2, \"dn\": []}, {\"tok\": \"kidding\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 3]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 2, \"dn\": [4]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 3, \"dn\": []}]}, {\"rt\": 1, \"toks\": [{\"tok\": \"You\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 6, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 3, \"dn\": []}, {\"tok\": \"sometimes\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": [2]}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 6, \"dn\": []}, {\"tok\": \"just\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": []}, {\"tok\": \"become\", \"tag\": \"VBP\", \"dep\": \"ccomp\", \"up\": 1, \"dn\": [3, 4, 5, 9]}, {\"tok\": \"this\", \"tag\": \"DT\", \"dep\": \"det\", \"up\": 9, \"dn\": []}, {\"tok\": \"\\\\\"\", \"tag\": \"``\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"persona\", \"tag\": \"NN\", \"dep\": \"attr\", \"up\": 6, \"dn\": [7, 8, 10]}, {\"tok\": \"\\\\\"\", \"tag\": \"\\'\\'\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": [12]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 11, \"dn\": []}]}, {\"rt\": 4, \"toks\": [{\"tok\": \"And\", \"tag\": \"CC\", \"dep\": \"cc\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"n\\'t\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 4, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 7, 8]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 7, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 7, \"dn\": []}, {\"tok\": \"quit\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 6]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
      "b'{\"id\": \"L869\", \"conversation_id\": \"L866\", \"text\": \"Like my fear of wearing pastels?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Like\", \"tag\": \"IN\", \"dep\": \"ROOT\", \"dn\": [2, 6]}, {\"tok\": \"my\", \"tag\": \"PRP$\", \"dep\": \"poss\", \"up\": 2, \"dn\": []}, {\"tok\": \"fear\", \"tag\": \"NN\", \"dep\": \"pobj\", \"up\": 0, \"dn\": [1, 3]}, {\"tok\": \"of\", \"tag\": \"IN\", \"dep\": \"prep\", \"up\": 2, \"dn\": [4]}, {\"tok\": \"wearing\", \"tag\": \"VBG\", \"dep\": \"pcomp\", \"up\": 3, \"dn\": [5]}, {\"tok\": \"pastels\", \"tag\": \"NNS\", \"dep\": \"dobj\", \"up\": 4, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L868\", \"timestamp\": null, \"vectors\": []}\\n'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import json\n",
    "\n",
    "corpus_name = \"movie-corpus\"\n",
    "corpus = os.path.join(\"data\", corpus_name)\n",
    "\n",
    "def printLines(file, n=10):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "printLines(os.path.join(corpus, \"utterances.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68206d8-cb8d-4062-aab5-7fa8dba88e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits each line of the file to create lines and conversations\n",
    "def loadLinesAndConversations(fileName, n):\n",
    "    lines = {}\n",
    "    conversations = {}\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            lineJson = json.loads(line)\n",
    "            # Extract fields for line object\n",
    "            lineObj = {}\n",
    "            lineObj[\"lineID\"] = lineJson[\"id\"] #example : L1045\n",
    "            lineObj[\"characterID\"] = lineJson[\"speaker\"] # example : u1, u2\n",
    "            lineObj[\"text\"] = lineJson[\"text\"] #These are the conversations\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "\n",
    "            # Extract fields for conversation object\n",
    "            if lineJson[\"conversation_id\"] not in conversations:\n",
    "                convObj = {}\n",
    "                convObj[\"conversationID\"] = lineJson[\"conversation_id\"]\n",
    "                convObj[\"movieID\"] = lineJson[\"meta\"][\"movie_id\"]\n",
    "                convObj[\"lines\"] = [lineObj]\n",
    "            else:\n",
    "                convObj = conversations[lineJson[\"conversation_id\"]]\n",
    "                convObj[\"lines\"].insert(0, lineObj)\n",
    "            conversations[convObj[\"conversationID\"]] = convObj\n",
    "    first_n_items = dict(itertools.islice(lines.items(), n))\n",
    "    print(first_n_items)\n",
    "    print(\"Line dictionary ends!! \\n\")\n",
    "    second_n_items = dict(itertools.islice(conversations.items(), n))\n",
    "    print(second_n_items)\n",
    "\n",
    "    return lines, conversations\n",
    "\n",
    "\n",
    "# Extracts pairs of sentences from conversations\n",
    "def extractSentencePairs(conversations):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations.values():\n",
    "        # Iterate over all the lines of the conversation\n",
    "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # Filter wrong samples (if one of the lists is empty)\n",
    "            if inputLine and targetLine:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf49aeb-fa3b-418c-b345-35b1525eed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus into lines and conversations...\n",
      "{'L1045': {'lineID': 'L1045', 'characterID': 'u0', 'text': 'They do not!'}, 'L1044': {'lineID': 'L1044', 'characterID': 'u2', 'text': 'They do to!'}, 'L985': {'lineID': 'L985', 'characterID': 'u0', 'text': 'I hope so.'}, 'L984': {'lineID': 'L984', 'characterID': 'u2', 'text': 'She okay?'}, 'L925': {'lineID': 'L925', 'characterID': 'u0', 'text': \"Let's go.\"}, 'L924': {'lineID': 'L924', 'characterID': 'u2', 'text': 'Wow'}, 'L872': {'lineID': 'L872', 'characterID': 'u0', 'text': \"Okay -- you're gonna need to learn how to lie.\"}, 'L871': {'lineID': 'L871', 'characterID': 'u2', 'text': 'No'}, 'L870': {'lineID': 'L870', 'characterID': 'u0', 'text': 'I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?'}, 'L869': {'lineID': 'L869', 'characterID': 'u0', 'text': 'Like my fear of wearing pastels?'}}\n",
      "Line dictionary ends!! \n",
      "\n",
      "{'L1044': {'conversationID': 'L1044', 'movieID': 'm0', 'lines': [{'lineID': 'L1044', 'characterID': 'u2', 'text': 'They do to!'}, {'lineID': 'L1045', 'characterID': 'u0', 'text': 'They do not!'}]}, 'L984': {'conversationID': 'L984', 'movieID': 'm0', 'lines': [{'lineID': 'L984', 'characterID': 'u2', 'text': 'She okay?'}, {'lineID': 'L985', 'characterID': 'u0', 'text': 'I hope so.'}]}, 'L924': {'conversationID': 'L924', 'movieID': 'm0', 'lines': [{'lineID': 'L924', 'characterID': 'u2', 'text': 'Wow'}, {'lineID': 'L925', 'characterID': 'u0', 'text': \"Let's go.\"}]}, 'L870': {'conversationID': 'L870', 'movieID': 'm0', 'lines': [{'lineID': 'L870', 'characterID': 'u0', 'text': 'I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?'}, {'lineID': 'L871', 'characterID': 'u2', 'text': 'No'}, {'lineID': 'L872', 'characterID': 'u0', 'text': \"Okay -- you're gonna need to learn how to lie.\"}]}, 'L866': {'conversationID': 'L866', 'movieID': 'm0', 'lines': [{'lineID': 'L866', 'characterID': 'u2', 'text': \"I figured you'd get to the good stuff eventually.\"}, {'lineID': 'L867', 'characterID': 'u0', 'text': 'What good stuff?'}, {'lineID': 'L868', 'characterID': 'u2', 'text': 'The \"real you\".'}, {'lineID': 'L869', 'characterID': 'u0', 'text': 'Like my fear of wearing pastels?'}]}, 'L862': {'conversationID': 'L862', 'movieID': 'm0', 'lines': [{'lineID': 'L862', 'characterID': 'u0', 'text': 'do you listen to this crap?'}, {'lineID': 'L863', 'characterID': 'u2', 'text': 'What crap?'}, {'lineID': 'L864', 'characterID': 'u0', 'text': \"Me.  This endless ...blonde babble. I'm like, boring myself.\"}, {'lineID': 'L865', 'characterID': 'u2', 'text': 'Thank God!  If I had to hear one more story about your coiffure...'}]}, 'L860': {'conversationID': 'L860', 'movieID': 'm0', 'lines': [{'lineID': 'L860', 'characterID': 'u0', 'text': 'Then Guillermo says, \"If you go any lighter, you\\'re gonna look like an extra on 90210.\"'}, {'lineID': 'L861', 'characterID': 'u2', 'text': 'No...'}]}, 'L696': {'conversationID': 'L696', 'movieID': 'm0', 'lines': [{'lineID': 'L696', 'characterID': 'u0', 'text': 'Well, no...'}, {'lineID': 'L697', 'characterID': 'u2', 'text': \"Then that's all you had to say.\"}, {'lineID': 'L698', 'characterID': 'u0', 'text': 'But'}, {'lineID': 'L699', 'characterID': 'u2', 'text': 'You always been this selfish?'}]}, 'L693': {'conversationID': 'L693', 'movieID': 'm0', 'lines': [{'lineID': 'L693', 'characterID': 'u2', 'text': 'I looked for you back at the party, but you always seemed to be \"occupied\".'}, {'lineID': 'L694', 'characterID': 'u0', 'text': 'I was?'}, {'lineID': 'L695', 'characterID': 'u2', 'text': \"You never wanted to go out with 'me, did you?\"}]}, 'L662': {'conversationID': 'L662', 'movieID': 'm0', 'lines': [{'lineID': 'L662', 'characterID': 'u2', 'text': 'Have fun tonight?'}, {'lineID': 'L663', 'characterID': 'u0', 'text': 'Tons'}]}}\n",
      "\n",
      "Writing newly formatted file...\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import itertools\n",
    "# Define path to new file\n",
    "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
    "\n",
    "delimiter = ','\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "# Initialize lines dict and conversations dict\n",
    "lines = {}\n",
    "conversations = {}\n",
    "# Load lines and conversations\n",
    "print(\"\\nProcessing corpus into lines and conversations...\")\n",
    "lines, conversations = loadLinesAndConversations(os.path.join(corpus, \"utterances.jsonl\"), 10)\n",
    "\n",
    "# Write new csv file\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "# with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "#     writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "#     for pair in extractSentencePairs(conversations):\n",
    "#         writer.writerow(pair)\n",
    "\n",
    "# # Print a sample of lines\n",
    "# print(\"\\nSample lines from file:\")\n",
    "# printLines(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f29ad7-4716-490c-9ca5-65641e14d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/movie-corpus/formatted_movie_lines.txt\")\n",
    "# Define the text to add\n",
    "import re\n",
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
    "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
    "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
    "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
    "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
    "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
    "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
    "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
    "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
    "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
    "    return txt\n",
    "df['Input'] = df['Input'].apply(lambda x: clean_text(x))\n",
    "df['Output'] = df['Output'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b59d99-87e7-4fe6-98bf-04632e9556f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>they do to</td>\n",
       "      <td>they do not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she okay</td>\n",
       "      <td>i hope so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow</td>\n",
       "      <td>lets go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am kidding  you know how sometimes you just ...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>okay  you are gonna need to learn how to lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221277</th>\n",
       "      <td>and i assure you you do not in fact i would be...</td>\n",
       "      <td>so far only their scouts but we have had repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221278</th>\n",
       "      <td>your orders mr vereker</td>\n",
       "      <td>i am to take the sikali with the main column t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221279</th>\n",
       "      <td>i am to take the sikali with the main column t...</td>\n",
       "      <td>lord chelmsford seems to want me to stay back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221280</th>\n",
       "      <td>lord chelmsford seems to want me to stay back ...</td>\n",
       "      <td>i think chelmsford wants a good man on the bor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221281</th>\n",
       "      <td>colonel durnford william vereker i hear you  h...</td>\n",
       "      <td>good ones yes mr vereker gentlemen who can rid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221282 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Input  \\\n",
       "0                                              they do to   \n",
       "1                                                she okay   \n",
       "2                                                     wow   \n",
       "3       i am kidding  you know how sometimes you just ...   \n",
       "4                                                      no   \n",
       "...                                                   ...   \n",
       "221277  and i assure you you do not in fact i would be...   \n",
       "221278                             your orders mr vereker   \n",
       "221279  i am to take the sikali with the main column t...   \n",
       "221280  lord chelmsford seems to want me to stay back ...   \n",
       "221281  colonel durnford william vereker i hear you  h...   \n",
       "\n",
       "                                                   Output  \n",
       "0                                             they do not  \n",
       "1                                               i hope so  \n",
       "2                                                 lets go  \n",
       "3                                                      no  \n",
       "4            okay  you are gonna need to learn how to lie  \n",
       "...                                                   ...  \n",
       "221277  so far only their scouts but we have had repor...  \n",
       "221278  i am to take the sikali with the main column t...  \n",
       "221279  lord chelmsford seems to want me to stay back ...  \n",
       "221280  i think chelmsford wants a good man on the bor...  \n",
       "221281  good ones yes mr vereker gentlemen who can rid...  \n",
       "\n",
       "[221282 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65fabefb-e5cf-4f43-a47b-569aeea71315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input     0\n",
       "Output    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c25c645b-e0bc-4f90-9bd1-69892b3f11b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa4014d-555b-453f-a0df-4032ff906c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_training, X_testing, y_training, y_testing = train_test_split(df['Input'], df['Output'], test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8cdcc1f-dae3-4298-8467-69f3f6e4c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_main_training, X_validation, y_main_training, y_validation = train_test_split(X_training, y_training, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a77323a-01a0-4862-a8a4-b1d5dba45130",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(X_main_training)\n",
    "train_df['Output'] = y_main_training\n",
    "train_df = train_df.reset_index()\n",
    "train_df = train_df.drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ddd055c-bf0d-40cb-9e87-be9394d65a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.DataFrame(X_validation)\n",
    "validation_df['Output'] = y_validation\n",
    "validation_df = validation_df.reset_index()\n",
    "validation_df = validation_df.drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89fbdc0f-73c2-40b5-8662-d1eec6dc8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(X_testing)\n",
    "test_df['Output'] = y_testing\n",
    "test_df = test_df.reset_index()\n",
    "test_df = test_df.drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5c6767c-ded3-41c2-8c4f-ce1e4f8b0715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input     0\n",
      "Output    0\n",
      "dtype: int64\n",
      "Input     0\n",
      "Output    0\n",
      "dtype: int64\n",
      "Input     0\n",
      "Output    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#train_df = train_df.reset_index()\n",
    "#train_df = train_df.drop(columns = ['index'])\n",
    "print(train_df.isnull().sum())\n",
    "print(validation_df.isnull().sum())\n",
    "print(test_df.isnull().sum())\n",
    "#train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcbe9d08-e109-40f6-b842-513a04fd320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of validation_df: (19916, 2)\n",
      "Shape of test_df: (22129, 2)\n",
      "Shape of train_df: (179237, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of validation_df: {validation_df.shape}')\n",
    "print(f'Shape of test_df: {test_df.shape}')\n",
    "print(f'Shape of train_df: {train_df.shape}')\n",
    "#print(train_df.shape[0] + validation_df.shape[0] + test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11a6926d-98e5-4e8d-9886-a8ca19b69a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "en_nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6675d8e-60c7-443b-a03a-32f904b32d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_inputs(x, en_nlp, max_length, lower, sos_token, eos_token):\n",
    "    input_tokens = [token.text for token in en_nlp.tokenizer(x)][:max_length]\n",
    "    if lower:\n",
    "        input_tokens = [token.lower() for token in input_tokens]\n",
    "    input_tokens = [sos_token] + input_tokens + [eos_token]\n",
    "    return input_tokens\n",
    "\n",
    "def tokenize_outputs(x, en_nlp, max_length, lower, sos_token, eos_token):\n",
    "    output_tokens = [token.text for token in en_nlp.tokenizer(x)][:max_length]\n",
    "    if lower:\n",
    "        output_tokens = [token.lower() for token in output_tokens]\n",
    "    output_tokens = [sos_token] + output_tokens + [eos_token]\n",
    "    return output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9745b89a-06fe-415c-88b9-920046b9b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = 1_000\n",
    "# en_tokens = [token.text for token in en_nlp.tokenizer(train_df[\"Input\"][0])][:max_length]\n",
    "# en_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bd51262-6b14-4010-90cf-22696147cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['input_token'] = train_df['Input'].map(lambda x:tokenize_inputs(x, en_nlp, 1000, True, '<sos>', '<eos>'))\n",
    "train_df['output_token'] = train_df['Output'].map(lambda x:tokenize_outputs(x, en_nlp, 1000, True, '<sos>', '<eos>'))\n",
    "validation_df['input_token'] = validation_df['Input'].map(lambda x:tokenize_inputs(x, en_nlp, 1000, True, '<sos>', '<eos>'))\n",
    "validation_df['output_token'] = validation_df['Output'].map(lambda x:tokenize_outputs(x, en_nlp, 1000, True, '<sos>', '<eos>'))\n",
    "test_df['input_token'] = test_df['Input'].map(lambda x:tokenize_inputs(x, en_nlp, 1000, True, '<sos>', '<eos>'))\n",
    "test_df['output_token'] = test_df['Output'].map(lambda x:tokenize_outputs(x, en_nlp, 1000, True, '<sos>', '<eos>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e90b6bea-b5e6-4487-8316-dc277368b284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "for i in train_df['output_token']:\n",
    "    current = 0\n",
    "    for j in i:\n",
    "        current += 1\n",
    "    if current > max:\n",
    "        max = current\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9adaadc5-7676-457b-9f1f-83a8b01231b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "      <th>input_token</th>\n",
       "      <th>output_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sir i have got an overload in disposal unit four</td>\n",
       "      <td>you better check on it mr dunn  i will stay he...</td>\n",
       "      <td>[&lt;sos&gt;, sir, i, have, got, an, overload, in, d...</td>\n",
       "      <td>[&lt;sos&gt;, you, better, check, on, it, mr, dunn, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is he italian</td>\n",
       "      <td>no why</td>\n",
       "      <td>[&lt;sos&gt;, is, he, italian, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, no, why, &lt;eos&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is this my fault do you think this is what i am</td>\n",
       "      <td>what</td>\n",
       "      <td>[&lt;sos&gt;, is, this, my, fault, do, you, think, t...</td>\n",
       "      <td>[&lt;sos&gt;, what, &lt;eos&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no no thank you</td>\n",
       "      <td>its a real good chocolate cake duncan hines de...</td>\n",
       "      <td>[&lt;sos&gt;, no, no, thank, you, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, its, a, real, good, chocolate, cake, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the premiere was the first time i have convinc...</td>\n",
       "      <td>viktor you should have said something</td>\n",
       "      <td>[&lt;sos&gt;, the, premiere, was, the, first, time, ...</td>\n",
       "      <td>[&lt;sos&gt;, viktor, you, should, have, said, somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179232</th>\n",
       "      <td>look you make this little run for me i will bu...</td>\n",
       "      <td>last year this was a new rig</td>\n",
       "      <td>[&lt;sos&gt;, look, you, make, this, little, run, fo...</td>\n",
       "      <td>[&lt;sos&gt;, last, year, this, was, a, new, rig, &lt;e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179233</th>\n",
       "      <td>actually the only thing i gotta give that guy ...</td>\n",
       "      <td>yeah well that pizza could feed a family of fo...</td>\n",
       "      <td>[&lt;sos&gt;, actually, the, only, thing, i, got, ta...</td>\n",
       "      <td>[&lt;sos&gt;, yeah, well, that, pizza, could, feed, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179234</th>\n",
       "      <td>i dont care what nobody says this bum creed wo...</td>\n",
       "      <td>hey how ya feelin mickey</td>\n",
       "      <td>[&lt;sos&gt;, i, do, nt, care, what, nobody, says, t...</td>\n",
       "      <td>[&lt;sos&gt;, hey, how, ya, feelin, mickey, &lt;eos&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179235</th>\n",
       "      <td>well what did he say</td>\n",
       "      <td>he said he thinks we have paid him and he want...</td>\n",
       "      <td>[&lt;sos&gt;, well, what, did, he, say, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, he, said, he, thinks, we, have, paid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179236</th>\n",
       "      <td>why are you saying it</td>\n",
       "      <td>its the only way it makes sense</td>\n",
       "      <td>[&lt;sos&gt;, why, are, you, saying, it, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, its, the, only, way, it, makes, sense,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179237 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Input  \\\n",
       "0        sir i have got an overload in disposal unit four   \n",
       "1                                           is he italian   \n",
       "2         is this my fault do you think this is what i am   \n",
       "3                                         no no thank you   \n",
       "4       the premiere was the first time i have convinc...   \n",
       "...                                                   ...   \n",
       "179232  look you make this little run for me i will bu...   \n",
       "179233  actually the only thing i gotta give that guy ...   \n",
       "179234  i dont care what nobody says this bum creed wo...   \n",
       "179235                               well what did he say   \n",
       "179236                              why are you saying it   \n",
       "\n",
       "                                                   Output  \\\n",
       "0       you better check on it mr dunn  i will stay he...   \n",
       "1                                                  no why   \n",
       "2                                                    what   \n",
       "3       its a real good chocolate cake duncan hines de...   \n",
       "4                   viktor you should have said something   \n",
       "...                                                   ...   \n",
       "179232                       last year this was a new rig   \n",
       "179233  yeah well that pizza could feed a family of fo...   \n",
       "179234                           hey how ya feelin mickey   \n",
       "179235  he said he thinks we have paid him and he want...   \n",
       "179236                    its the only way it makes sense   \n",
       "\n",
       "                                              input_token  \\\n",
       "0       [<sos>, sir, i, have, got, an, overload, in, d...   \n",
       "1                         [<sos>, is, he, italian, <eos>]   \n",
       "2       [<sos>, is, this, my, fault, do, you, think, t...   \n",
       "3                      [<sos>, no, no, thank, you, <eos>]   \n",
       "4       [<sos>, the, premiere, was, the, first, time, ...   \n",
       "...                                                   ...   \n",
       "179232  [<sos>, look, you, make, this, little, run, fo...   \n",
       "179233  [<sos>, actually, the, only, thing, i, got, ta...   \n",
       "179234  [<sos>, i, do, nt, care, what, nobody, says, t...   \n",
       "179235           [<sos>, well, what, did, he, say, <eos>]   \n",
       "179236          [<sos>, why, are, you, saying, it, <eos>]   \n",
       "\n",
       "                                             output_token  \n",
       "0       [<sos>, you, better, check, on, it, mr, dunn, ...  \n",
       "1                                 [<sos>, no, why, <eos>]  \n",
       "2                                    [<sos>, what, <eos>]  \n",
       "3       [<sos>, its, a, real, good, chocolate, cake, d...  \n",
       "4       [<sos>, viktor, you, should, have, said, somet...  \n",
       "...                                                   ...  \n",
       "179232  [<sos>, last, year, this, was, a, new, rig, <e...  \n",
       "179233  [<sos>, yeah, well, that, pizza, could, feed, ...  \n",
       "179234       [<sos>, hey, how, ya, feelin, mickey, <eos>]  \n",
       "179235  [<sos>, he, said, he, thinks, we, have, paid, ...  \n",
       "179236  [<sos>, its, the, only, way, it, makes, sense,...  \n",
       "\n",
       "[179237 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7235bbd6-9c77-4b65-94af-bf24d3c60928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb851a73-02a5-4f13-ad46-6458a2ac0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "859edabe-14c1-480f-a3ed-e45580f83966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Arun\\Machine Learning\\VirtualEnvProjects\\PyTorch\\torch\\Lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "C:\\Arun\\Machine Learning\\VirtualEnvProjects\\PyTorch\\torch\\Lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4335c6f-8a09-40bb-afdd-1ad0e260e37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358474,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_data = pd.concat([train_df['input_token'], train_df['output_token']])\n",
    "concat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f34c15f-5665-4380-8485-904ad5ff75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 4\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    '<sos>',\n",
    "    '<eos>',\n",
    "]\n",
    "\n",
    "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    concat_data,\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "# de_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "#     train_data[\"de_tokens\"],\n",
    "#     min_freq=min_freq,\n",
    "#     specials=special_tokens,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e3eb357-b76f-49f7-af7a-374360c548f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(en_vocab['<sos>'])\n",
    "print(en_vocab['<eos>'])\n",
    "print(en_vocab['<unk>'])\n",
    "print(en_vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58b9c0ec-22d2-4b0f-b712-92c5a0858481",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(en_vocab['<unk>'])\n",
    "#de_vocab.set_default_index(de_vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b12210f-9a1e-46a0-aa34-c3f8e2efafaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 137, 806, 1009, 1385]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\n",
    "en_vocab.lookup_indices(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c88e273e-48e3-4763-b30f-877d712b287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_english(example, en_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example)\n",
    "    return en_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ea51966-4df9-451b-97e2-dfe8cfff3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['input_ids'] = train_df['input_token'].map(lambda x:numericalize_english(x, en_vocab))\n",
    "train_df['output_ids'] = train_df['output_token'].map(lambda x:numericalize_english(x, en_vocab))\n",
    "validation_df['input_ids'] = validation_df['input_token'].map(lambda x:numericalize_english(x, en_vocab))\n",
    "validation_df['output_ids'] = validation_df['output_token'].map(lambda x:numericalize_english(x, en_vocab))\n",
    "test_df['input_ids'] = test_df['input_token'].map(lambda x:numericalize_english(x, en_vocab))\n",
    "test_df['output_ids'] = test_df['output_token'].map(lambda x:numericalize_english(x, en_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c82ce23-d811-496c-8e54-939164da0807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "      <th>input_token</th>\n",
       "      <th>output_token</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>output_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sir i have got an overload in disposal unit four</td>\n",
       "      <td>you better check on it mr dunn  i will stay he...</td>\n",
       "      <td>[&lt;sos&gt;, sir, i, have, got, an, overload, in, d...</td>\n",
       "      <td>[&lt;sos&gt;, you, better, check, on, it, mr, dunn, ...</td>\n",
       "      <td>[2, 145, 5, 20, 50, 78, 13872, 19, 6082, 2236,...</td>\n",
       "      <td>[2, 4, 161, 448, 35, 11, 131, 12512, 6, 5, 28,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is he italian</td>\n",
       "      <td>no why</td>\n",
       "      <td>[&lt;sos&gt;, is, he, italian, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, no, why, &lt;eos&gt;]</td>\n",
       "      <td>[2, 10, 24, 1938, 3]</td>\n",
       "      <td>[2, 33, 67, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is this my fault do you think this is what i am</td>\n",
       "      <td>what</td>\n",
       "      <td>[&lt;sos&gt;, is, this, my, fault, do, you, think, t...</td>\n",
       "      <td>[&lt;sos&gt;, what, &lt;eos&gt;]</td>\n",
       "      <td>[2, 10, 26, 32, 708, 12, 4, 59, 26, 10, 18, 5,...</td>\n",
       "      <td>[2, 18, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no no thank you</td>\n",
       "      <td>its a real good chocolate cake duncan hines de...</td>\n",
       "      <td>[&lt;sos&gt;, no, no, thank, you, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, its, a, real, good, chocolate, cake, d...</td>\n",
       "      <td>[2, 33, 33, 211, 4, 3]</td>\n",
       "      <td>[2, 36, 9, 222, 79, 2545, 2276, 7294, 21090, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the premiere was the first time i have convinc...</td>\n",
       "      <td>viktor you should have said something</td>\n",
       "      <td>[&lt;sos&gt;, the, premiere, was, the, first, time, ...</td>\n",
       "      <td>[&lt;sos&gt;, viktor, you, should, have, said, somet...</td>\n",
       "      <td>[2, 7, 11236, 30, 7, 158, 85, 5, 20, 2814, 66,...</td>\n",
       "      <td>[2, 2775, 4, 115, 20, 116, 101, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179232</th>\n",
       "      <td>look you make this little run for me i will bu...</td>\n",
       "      <td>last year this was a new rig</td>\n",
       "      <td>[&lt;sos&gt;, look, you, make, this, little, run, fo...</td>\n",
       "      <td>[&lt;sos&gt;, last, year, this, was, a, new, rig, &lt;e...</td>\n",
       "      <td>[2, 95, 4, 105, 26, 108, 293, 27, 21, 5, 28, 4...</td>\n",
       "      <td>[2, 162, 375, 26, 30, 9, 184, 4030, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179233</th>\n",
       "      <td>actually the only thing i gotta give that guy ...</td>\n",
       "      <td>yeah well that pizza could feed a family of fo...</td>\n",
       "      <td>[&lt;sos&gt;, actually, the, only, thing, i, got, ta...</td>\n",
       "      <td>[&lt;sos&gt;, yeah, well, that, pizza, could, feed, ...</td>\n",
       "      <td>[2, 376, 7, 121, 118, 5, 50, 216, 132, 14, 170...</td>\n",
       "      <td>[2, 76, 62, 14, 2988, 75, 1511, 9, 370, 16, 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179234</th>\n",
       "      <td>i dont care what nobody says this bum creed wo...</td>\n",
       "      <td>hey how ya feelin mickey</td>\n",
       "      <td>[&lt;sos&gt;, i, do, nt, care, what, nobody, says, t...</td>\n",
       "      <td>[&lt;sos&gt;, hey, how, ya, feelin, mickey, &lt;eos&gt;]</td>\n",
       "      <td>[2, 5, 12, 13, 236, 18, 365, 282, 26, 2409, 56...</td>\n",
       "      <td>[2, 180, 56, 274, 3272, 1754, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179235</th>\n",
       "      <td>well what did he say</td>\n",
       "      <td>he said he thinks we have paid him and he want...</td>\n",
       "      <td>[&lt;sos&gt;, well, what, did, he, say, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, he, said, he, thinks, we, have, paid, ...</td>\n",
       "      <td>[2, 62, 18, 45, 24, 89, 3]</td>\n",
       "      <td>[2, 24, 116, 24, 581, 23, 20, 695, 55, 15, 24,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179236</th>\n",
       "      <td>why are you saying it</td>\n",
       "      <td>its the only way it makes sense</td>\n",
       "      <td>[&lt;sos&gt;, why, are, you, saying, it, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;sos&gt;, its, the, only, way, it, makes, sense,...</td>\n",
       "      <td>[2, 67, 17, 4, 290, 11, 3]</td>\n",
       "      <td>[2, 36, 7, 121, 102, 11, 349, 537, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179237 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Input  \\\n",
       "0        sir i have got an overload in disposal unit four   \n",
       "1                                           is he italian   \n",
       "2         is this my fault do you think this is what i am   \n",
       "3                                         no no thank you   \n",
       "4       the premiere was the first time i have convinc...   \n",
       "...                                                   ...   \n",
       "179232  look you make this little run for me i will bu...   \n",
       "179233  actually the only thing i gotta give that guy ...   \n",
       "179234  i dont care what nobody says this bum creed wo...   \n",
       "179235                               well what did he say   \n",
       "179236                              why are you saying it   \n",
       "\n",
       "                                                   Output  \\\n",
       "0       you better check on it mr dunn  i will stay he...   \n",
       "1                                                  no why   \n",
       "2                                                    what   \n",
       "3       its a real good chocolate cake duncan hines de...   \n",
       "4                   viktor you should have said something   \n",
       "...                                                   ...   \n",
       "179232                       last year this was a new rig   \n",
       "179233  yeah well that pizza could feed a family of fo...   \n",
       "179234                           hey how ya feelin mickey   \n",
       "179235  he said he thinks we have paid him and he want...   \n",
       "179236                    its the only way it makes sense   \n",
       "\n",
       "                                              input_token  \\\n",
       "0       [<sos>, sir, i, have, got, an, overload, in, d...   \n",
       "1                         [<sos>, is, he, italian, <eos>]   \n",
       "2       [<sos>, is, this, my, fault, do, you, think, t...   \n",
       "3                      [<sos>, no, no, thank, you, <eos>]   \n",
       "4       [<sos>, the, premiere, was, the, first, time, ...   \n",
       "...                                                   ...   \n",
       "179232  [<sos>, look, you, make, this, little, run, fo...   \n",
       "179233  [<sos>, actually, the, only, thing, i, got, ta...   \n",
       "179234  [<sos>, i, do, nt, care, what, nobody, says, t...   \n",
       "179235           [<sos>, well, what, did, he, say, <eos>]   \n",
       "179236          [<sos>, why, are, you, saying, it, <eos>]   \n",
       "\n",
       "                                             output_token  \\\n",
       "0       [<sos>, you, better, check, on, it, mr, dunn, ...   \n",
       "1                                 [<sos>, no, why, <eos>]   \n",
       "2                                    [<sos>, what, <eos>]   \n",
       "3       [<sos>, its, a, real, good, chocolate, cake, d...   \n",
       "4       [<sos>, viktor, you, should, have, said, somet...   \n",
       "...                                                   ...   \n",
       "179232  [<sos>, last, year, this, was, a, new, rig, <e...   \n",
       "179233  [<sos>, yeah, well, that, pizza, could, feed, ...   \n",
       "179234       [<sos>, hey, how, ya, feelin, mickey, <eos>]   \n",
       "179235  [<sos>, he, said, he, thinks, we, have, paid, ...   \n",
       "179236  [<sos>, its, the, only, way, it, makes, sense,...   \n",
       "\n",
       "                                                input_ids  \\\n",
       "0       [2, 145, 5, 20, 50, 78, 13872, 19, 6082, 2236,...   \n",
       "1                                    [2, 10, 24, 1938, 3]   \n",
       "2       [2, 10, 26, 32, 708, 12, 4, 59, 26, 10, 18, 5,...   \n",
       "3                                  [2, 33, 33, 211, 4, 3]   \n",
       "4       [2, 7, 11236, 30, 7, 158, 85, 5, 20, 2814, 66,...   \n",
       "...                                                   ...   \n",
       "179232  [2, 95, 4, 105, 26, 108, 293, 27, 21, 5, 28, 4...   \n",
       "179233  [2, 376, 7, 121, 118, 5, 50, 216, 132, 14, 170...   \n",
       "179234  [2, 5, 12, 13, 236, 18, 365, 282, 26, 2409, 56...   \n",
       "179235                         [2, 62, 18, 45, 24, 89, 3]   \n",
       "179236                         [2, 67, 17, 4, 290, 11, 3]   \n",
       "\n",
       "                                               output_ids  \n",
       "0       [2, 4, 161, 448, 35, 11, 131, 12512, 6, 5, 28,...  \n",
       "1                                          [2, 33, 67, 3]  \n",
       "2                                              [2, 18, 3]  \n",
       "3       [2, 36, 9, 222, 79, 2545, 2276, 7294, 21090, 3...  \n",
       "4                      [2, 2775, 4, 115, 20, 116, 101, 3]  \n",
       "...                                                   ...  \n",
       "179232             [2, 162, 375, 26, 30, 9, 184, 4030, 3]  \n",
       "179233  [2, 76, 62, 14, 2988, 75, 1511, 9, 370, 16, 32...  \n",
       "179234                   [2, 180, 56, 274, 3272, 1754, 3]  \n",
       "179235  [2, 24, 116, 24, 581, 23, 20, 695, 55, 15, 24,...  \n",
       "179236              [2, 36, 7, 121, 102, 11, 349, 537, 3]  \n",
       "\n",
       "[179237 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71a8bba2-bc59-4400-a9e2-5d3cad2a612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_data = Dataset.from_pandas(train_df)\n",
    "test_data =  Dataset.from_pandas(test_df)\n",
    "validation_data = Dataset.from_pandas(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42f87d36-d1ab-4420-a5de-7954688fac36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Input', 'Output', 'input_token', 'output_token', 'input_ids', 'output_ids'],\n",
       "    num_rows: 179237\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "384cb923-fec3-4d19-abd3-5b4b6736b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"input_ids\", \"output_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "validation_data = validation_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_data = test_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a90d5a1c-d9a2-4422-9f85-bb170e16a6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    2,   145,     5,    20,    50,    78, 13872,    19,  6082,  2236,\n",
       "           323,     3]),\n",
       " 'output_ids': tensor([    2,     4,   161,   448,    35,    11,   131, 12512,     6,     5,\n",
       "            28,   237,    54,    15,   992,     7,   567,     3]),\n",
       " 'Input': 'sir i have got an overload in disposal unit four',\n",
       " 'Output': 'you better check on it mr dunn  i will stay here and fly the ship',\n",
       " 'input_token': ['<sos>',\n",
       "  'sir',\n",
       "  'i',\n",
       "  'have',\n",
       "  'got',\n",
       "  'an',\n",
       "  'overload',\n",
       "  'in',\n",
       "  'disposal',\n",
       "  'unit',\n",
       "  'four',\n",
       "  '<eos>'],\n",
       " 'output_token': ['<sos>',\n",
       "  'you',\n",
       "  'better',\n",
       "  'check',\n",
       "  'on',\n",
       "  'it',\n",
       "  'mr',\n",
       "  'dunn',\n",
       "  ' ',\n",
       "  'i',\n",
       "  'will',\n",
       "  'stay',\n",
       "  'here',\n",
       "  'and',\n",
       "  'fly',\n",
       "  'the',\n",
       "  'ship',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92504cbe-0b78-4873-8b0d-fc264d2497d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_index = 1 #Vocab Pad Index value\n",
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"input_ids\"] for example in batch]\n",
    "        batch_de_ids = [example[\"output_ids\"] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"input_ids\": batch_en_ids,\n",
    "            \"output_ids\": batch_de_ids,\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de1333c8-80c1-4a64-aa15-1ee0e95a2f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40bf492f-6686-409c-99a6-188bc5c0f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "validation_data_loader = get_data_loader(validation_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f354e135-8783-4e0f-87c9-1c0594c76861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum = 0\n",
    "# count = 0\n",
    "# batch_number = 0\n",
    "# for batch in train_data_loader:\n",
    "#   batch_number +=1\n",
    "#   # inputs = batch['en_ids']\n",
    "#   # output = batch['de_ids']\n",
    "#   #print(f'This is the batch: {batch}')\n",
    "#   for input in batch['input_ids']:\n",
    "#     #print(len(input))\n",
    "#   # print(f'This is the input {inputs}')\n",
    "#   # print(f'This is the output: {output}')\n",
    "#     sum +=1\n",
    "#   print(f'This is the size of each batch:{sum}')\n",
    "#   sum = 0\n",
    "#   count +=1\n",
    "\n",
    "# print(batch_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c92618e-dafd-470a-84c6-e5ad915111bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b3b2897-afa0-49f6-9032-07720925e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # context = [n layers, batch size, hidden dim]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # output = [seq length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # seq length and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, hidden dim]\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # cell = [n layers, batch size, hidden dim]\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "069a91fa-1a1a-420b-bec5-45484414d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert (\n",
    "            encoder.n_layers == decoder.n_layers\n",
    "        ), \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = trg[0, :]\n",
    "        \n",
    "        for t in range(1, trg_length):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            # Apply softmax to the output logits\n",
    "            output_probs = nn.functional.softmax(output, dim=1)\n",
    "            # Get the most probable token indices\n",
    "            top1 = output_probs.argmax(1)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5995562e-9a42-4264-9d22-5c204c99ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(en_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 128\n",
    "decoder_embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    decoder_dropout,\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fd80c17-176f-4d6c-ba79-a10eb76cacbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(23068, 128)\n",
       "    (rnn): LSTM(128, 256, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(23068, 128)\n",
       "    (rnn): LSTM(128, 256, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=256, out_features=23068, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd361983-8291-47e9-be0d-4d9b7c962fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45648fb3-3304-4d38-8284-7aed0434cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        src = batch[\"input_ids\"].to(device)\n",
    "        trg = batch[\"output_ids\"].to(device)\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d3f35a5-ae95-4aa9-9c8c-a0261bfe0623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"input_ids\"].to(device)\n",
    "            trg = batch[\"output_ids\"].to(device)\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, trg, 0)  # turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "670dcddc-713f-40ab-96ba-5eb44b19b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b1a0af5-2dd0-41db-a2a3-c15255b972a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/10 [1:03:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m best_valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(n_epochs)):\n\u001b[1;32m----> 8\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evaluate_fn(\n\u001b[0;32m     18\u001b[0m         model,\n\u001b[0;32m     19\u001b[0m         valid_data_loader,\n\u001b[0;32m     20\u001b[0m         criterion,\n\u001b[0;32m     21\u001b[0m         device,\n\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_loss \u001b[38;5;241m<\u001b[39m best_valid_loss:\n",
      "Cell \u001b[1;32mIn[47], line 12\u001b[0m, in \u001b[0;36mtrain_fn\u001b[1;34m(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# src = [src length, batch size]\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# trg = [trg length, batch size]\u001b[39;00m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# output = [trg length, batch size, trg vocab size]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mC:\\Arun\\Machine Learning\\VirtualEnvProjects\\PyTorch\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Arun\\Machine Learning\\VirtualEnvProjects\\PyTorch\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[43], line 30\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[1;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m     28\u001b[0m output_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Get the most probable token indices\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m top1 \u001b[38;5;241m=\u001b[39m \u001b[43moutput_probs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m outputs[t] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m     32\u001b[0m teacher_force \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m teacher_forcing_ratio\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"tut1-model.pt\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ddc580-d349-4267-82f4-6e11a0533e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
